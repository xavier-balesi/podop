{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Everything starts with understanding the product owner, or not...</p>"},{"location":"#test-statement-interpretation","title":"Test statement interpretation","text":"<p>The game stops when you reach 30 robots.</p> <p>It's then a game.</p> <p>A second for the robot does not have to be a real-life second.</p> <p>The game should include a time acceleration feature. The primary objective appears to be maximizing profit as quickly as possible, as robots operate concurrently to generate revenue by selling resources.</p> <p>A console output is enough.</p> <p>A game is for gamers, and gamers need an output.</p> <p>There is no need to do complex math to solve the problem; we do not need the action choice to be optimal, just a working production line.</p> <p>Only developers have the ability to optimize the actions in the action game (the robots' movements). Gamers simply press buttons on their console to challenge opponents in real-time strategy (RTS) games.</p> <p>If the goal isn't to optimize moves with mathematics, why not delegate the task to a bot? Unfortunately, the video game publisher isn't available to clarify their intentions regarding the game, but let's propose a game that would be enjoyable to play.</p> <p>I'm a chess player and the competitions are divided into two categories: one for humans, one for machines. Creating the best bot could be even more interesting and challenging than traditional gameplay.</p> <p>Therefore, my objective for this exercise is to develop a game engine that aligns with the given requirements. If time permits, I aim to create a web interface where players can design and share their bot's performances with other competitors. The game should be accessible to non-data scientists, limiting players to adjusting the reward rules of a single reinforcement learning model. Rewards serve to help the bot understand game rules and facilitate convergence during the learning phase.</p> <p>While it may not directly meet the needs of the game publisher, it aligns with my roadmap for skill improvement \ud83d\ude04. Additionally, deep reinforcement learning is also utilized for trading automation in the stock market and cryptocurrencies, making this exercise quite interesting due to its links with finance.</p>"},{"location":"#technical-decisions","title":"Technical decisions","text":""},{"location":"#frontend","title":"Frontend","text":"<p>Opting for a command-line interface (CLI), text-based user interfaces (TUI), or desktop interface (using QT or pygame) doesn't align with my goal of showcasing skills in cloud environments.</p> <p>Personally, I would have preferred utilizing Flutter for its multi-platform capabilities and superior graphical rendering performance achieved by drawing directly on the device's canvas with the Skia rendering engine. This stands in contrast to React Native, which relies on Java native libraries. However, due to my stronger understanding of JavaScript compared to Dart, I have chosen to focus on learning Next.js , which is currently in vogue.</p> <p>For the time being, the front end could be compiled into a static website and served via Google Cloud Storage, AWS S3 bucket, or a simple Nginx server. However, in anticipation of integrating an identity and access management solution for player authentication, I have opted to utilize the standard Node server provided by Next.js to handle authentication requests on the server side, thereby avoiding the need to store access tokens on the client side.</p>"},{"location":"#backend","title":"Backend","text":"<p>The performance of the bot improves with each game it plays. Hence, relying on OS schedulers to orchestrate the robot's actions is not viable. The time should be entirely simulated, without intentional pauses between moves, even if only for a few milliseconds. This approach ensures maximal CPU utilization.</p> <p>While I would have preferred to code the game engine in Rust, I had to work within the constraint of using Python. To overcome the Global Interpreter Lock (GIL) limitation during bot training, I set up a Kubernetes cluster locally with horizontal pod autoscaling (HPA). While process-based parallelism using the <code>multiprocessing</code> Python module would suffice with only one local machine, I sought a more challenging solution.</p> <p>For communication between the backend and frontend, I opted for WebSocket for its flexibility. In the event that the game publisher does not accept the proposed game and prefers a standard real-time strategy game, WebSocket provides bidirectional communication and ease of setup compared to double WebHook communication or REST combined with Server-Sent-Events (SSE). Furthermore, WebSocket reduces latency by minimizing handshakes and ensures better reliability through perpetual communication.</p> <p>I structured the code using the Command and Query Responsibility Segregation (CQRS) and Event Sourcing patterns. Robots in the game emit Transaction events, which serve as the primary source of game outputs. The Inventory class organizes the data for future readings. This organization can be generalized at the system architecture scale and is adaptable. For instance, if we require traceability of in-game events, we can register for Transaction events and store them in a database or lakehouse for analysis by data scientists. To enhance throughput, we can implement an intermediary such as a message broker (e.g., Kafka, Pulsar). While Redis offers better performance, message brokers ensure message storage for each sent message, whereas Redis may risk losing one second of data.</p> <p>In collaboration with the Python guild of my company, we selected PDM as the project manager over Poetry and Hatch. PDM is fully PEP compliant (PEP-621), slightly more performant than Poetry, and supports project templates. As long as essential functionality (e.g., dependency grouping and locking) is available, any project manager suffices for me. Achieving consensus within the company on tool selection is paramount to avoid tool proliferation and multiple CI/CD implementations. My apologies in advance to Poetry enthusiasts \ud83d\ude0a.</p>"},{"location":"conclusion/","title":"Conclusion","text":""},{"location":"conclusion/#past-and-future-roadmap","title":"Past and future roadmap","text":"<ul> <li> Update my personal project template<ul> <li> Migrate from Sphinx to MkDocs</li> <li> Migrate from Autoflake, Black, Flake8, Isort, Pylint to Ruff</li> <li> Replace home-made logger with an open source logger like structlog if iso functional</li> <li> Create tests from documentation examples using doctest module</li> </ul> </li> <li> Use GitHub for the first time<ul> <li> Integration with Codecov</li> <li> Integration with Docker.com registry</li> </ul> </li> <li> Implement the game engine according to the test statement<ul> <li> Implement a fake delay scheduler optimized for performance</li> </ul> </li> <li> Discover Next.js to build the frontend<ul> <li> Update a chart in live with game engine info, by using a WebSocket </li> </ul> </li> <li> Tests<ul> <li> 99% of branch coverage</li> <li> Charting benchmark data historically on GitHub Pages</li> <li> Profile CPU execution</li> <li> Verify memory leaks automatically</li> <li> Profile memory usage</li> </ul> </li> <li> Documentation<ul> <li> Docstrings for all classes, private and public methods, attributes, parameters in Google format</li> <li> Markdown documentation</li> <li> Integrate the code coverage in the documentation</li> <li> Deploy the documentation on GitHub Pages</li> </ul> </li> <li> CI/CD<ul> <li> Verify tests with GitHub Actions workflows</li> <li> Build docker images with GitHub Actions workflows</li> <li> Deployment with Docker Compose</li> <li> Deployment in a local Kubernetes cluster</li> <li> Setup horizontal dynamic scaling</li> </ul> </li> <li> Observability<ul> <li> Enhance logging by adding extra info in log contexts</li> <li> Visualize logs and traces when CPU &gt; 90% with OpenTelemetry<ul> <li> Setup Prometheus</li> <li> Setup Grafana</li> <li> Setup Jaeger</li> <li> Setup Loki</li> <li> Instrument the code (I only have instrumented logs in a feature branch)</li> </ul> </li> </ul> </li> <li> Explore the history of all games of all competitors from the frontend<ul> <li> Authenticate the end users</li> <li> Export game data to a database or a lakehouse</li> <li> Serve this data with GraphQL to see if users are no more interested in some data</li> </ul> </li> <li> Display best game scores by country and worldwide</li> <li> Train a bot from the frontend<ul> <li> Create a deep reinforcement learning model<ul> <li> Reproduce reinforcement learning make for simple strategy games like Santori (where the goal is also to finish the game rapidly)</li> <li> Idem with Connect 4 but rewards are made so the game last longer...</li> <li> Maybe venture out with the Deep RTS research project</li> </ul> </li> <li> Choose the rewards from the frontend</li> </ul> </li> </ul>"},{"location":"conclusion/#feedback","title":"Feedback","text":"<p>I really enjoyed testing the tools in vogue at the moment. Compared to a few years ago, the setup is much faster, in particular because the documentation is much better. I will reuse most of them for my personal future projects.</p> <p>The exercise was very interesting, and I'll continue to train a bot for this game for sure.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#installing-docker-compose-v1","title":"Installing Docker Compose V1","text":"<p>I personally use Docker Engine v24.0.5 and Docker Compose v1.29.2, installed by Ubuntu packets <code>docker.io</code> and <code>docker-compose</code>. In case you don't have root privileges on your machine, you can install Docker Compose like explained here.</p>"},{"location":"usage/#run-with-docker-compose-v1","title":"Run with Docker Compose V1","text":"<ol> <li>run <code>docker-compose up --build</code> from the root directory</li> <li>open http://localhost:3000/</li> </ol> <p>To see robots' movements in the logs, you can restart with:</p> <p><code>LOG_FILTER='debug:.*robot' LOG_FORMAT=debug LOG_LEVEL=warning docker-compose up</code>.</p> <p>These fields are documented in the home-made logger documentation. I'm sorry because the documentation of the generic library won't render correctly because it is still at the Sphinx format, not at the Google docstring format as made for the new code base created for this take-home coding test.</p>"},{"location":"usage/#install-kind-and-helm","title":"Install Kind and Helm","text":"<p>Kind permits to create a local Kubernetes cluster. It is more performant than Minikube as it uses Docker instead of a virtual machine. To install Kind, follow the Kind official documentation.</p> <p>To install Helm, the package manager for Kubernetes, there is an Helm official documentation too.</p> <p>In case you don't have root privileges on your machine, assuming <code>~/.local/bin</code> is listed in <code>echo $PATH</code>, you can execute these commands:</p> <pre><code>cd /tmp\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nchmod 700 get_helm.sh\nmkdir -p ~/.local/bin 2&gt;/dev/null\nUSE_SUDO=false HELM_INSTALL_DIR=\"${HOME}/.local/bin\" ./get_helm.sh\n~/.local/bin/helm plugin install https://github.com/databus23/helm-diff\n</code></pre>"},{"location":"usage/#deploy-in-a-local-kubernetes-cluster","title":"Deploy in a local Kubernetes cluster","text":"<ol> <li>run <code>./k8s/create_cluster.sh</code> and copy the Headlamp token displayed</li> <li>open http://headlamp.127.0.0.1.nip.io/c/main/pods</li> <li>paste the token (refresh the page if Headlamp displays an error and is not asking for the token)</li> <li>if Headlamp ask for a new token after a while, run <code>kubectl create token headlamp-admin -n kube-system</code> to regenerate it</li> <li>run <code>./k8s/deploy.sh</code></li> <li>open http://foobartory-front.127.0.0.1.nip.io/</li> <li>run <code>kind delete cluster</code> to delete the cluster when you are done (please check next sections first)</li> </ol>"},{"location":"usage/#test-horizontal-pod-autoscaling","title":"Test Horizontal Pod Autoscaling","text":"<p>You can open five tabs of the frontend URL in the browser, switch from tab, refresh the page and redo the operation multiple times (maintain Ctrl down all the time and chain Page Up/Down, followed by F5). You will see new pods of the backend in Headlamp. If you have kubectl, you can see the current utilisation of CPU and the number of replicas with this command: <code>kubectl get --namespace foobartory hpa foobartory-back --watch</code>.</p> <pre><code>NAME              TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\nfoobartory-back   2%/5%     1         5         1          4h49m\nfoobartory-back   36%/5%    1         5         1          4h50m\nfoobartory-back   100%/5%   1         5         4          4h50m\nfoobartory-back   78%/5%    1         5         5          4h50m\nfoobartory-back   36%/5%    1         5         5          4h50m\nfoobartory-back   2%/5%     1         5         5          4h51m\nfoobartory-back   2%/5%     1         5         5          4h55m\nfoobartory-back   2%/5%     1         5         2          4h56m\nfoobartory-back   2%/5%     1         5         2          4h57m\nfoobartory-back   42%/5%    1         5         2          4h57m\nfoobartory-back   42%/5%    1         5         4          4h58m\nfoobartory-back   16%/5%    1         5         5          4h58m\nfoobartory-back   25%/5%    1         5         5          4h58m\nfoobartory-back   2%/5%     1         5         5          4h58m\n</code></pre>"},{"location":"usage/#play-the-game","title":"Play the game","text":"<p>The objective of the game is to reach 30 robots in the shortest possible time. The frontend displays the following chart:</p> <p></p> <p>We can observe that the game ends precisely after 886,193 milliseconds (e.g., 14 minutes and 46 seconds). Additionally, it's apparent that the player is generating an excessive number of bars and money, while foos are lacking.</p> <p>For the moment, there is no discernible strategy in place, this result makes sense. Robots move randomly, resulting in an equal distribution of foos and bars. However, this distribution doesn't align with the game rules, which require 3\u20ac and 6 foos to purchase a robot.</p> <p>We could enhance the strategy by prioritizing foos mining. An interesting feature, would be to define and test strategies in real-time from the frontend.</p> <p>I am more enthusiastic about the prospect of training a bot from the frontend using deep reinforcement learning algorithms to automatically devise the most effective strategy. In the next section, I will outline the features I would like to implement with additional time.</p>"},{"location":"api_reference/generic_library/","title":"Generic library","text":""},{"location":"api_reference/generic_library/#generic_lib","title":"generic_lib","text":""},{"location":"api_reference/generic_library/#generic_lib.dict_facilities","title":"dict_facilities","text":"<p>This module proposes utilities around dictionaries.</p>"},{"location":"api_reference/generic_library/#generic_lib.dict_facilities.dict_merge","title":"dict_merge","text":"<pre><code>dict_merge(dct, merge_dct)\n</code></pre> <p>Recursive <code>dict</code> merge.</p> <p>Inspired by <code>dict.update()</code>, instead of updating only top-level keys, dict_merge recurse down into dicts nested to an arbitrary depth, updating keys. The <code>merge_dct</code> is merged into <code>dct</code>.</p> <p>https://gist.githubusercontent.com/angstwad/bf22d1822c38a92ec0a9/raw/dbb0d3e7b0640be0237bd72058ddd8f84788b583/dict_merge.py</p> <p>:param dct: :class:<code>dict</code> onto which the merge is executed :param merge_dct: dct merged into dct :return: None</p> Source code in <code>src/generic_lib/dict_facilities.py</code> <pre><code>def dict_merge(dct: dict[Any, Any], merge_dct: dict[Any, Any]) -&gt; None:\n    \"\"\"Recursive `dict` merge.\n\n    Inspired by `dict.update()`, instead of\n    updating only top-level keys, dict_merge recurse down into dicts nested\n    to an arbitrary depth, updating keys. The ``merge_dct`` is merged into\n    ``dct``.\n\n    https://gist.githubusercontent.com/angstwad/bf22d1822c38a92ec0a9/raw/dbb0d3e7b0640be0237bd72058ddd8f84788b583/dict_merge.py\n\n    :param dct: :class:`dict` onto which the merge is executed\n    :param merge_dct: dct merged into dct\n    :return: None\n    \"\"\"\n    for k, v in merge_dct.items():\n        if k in dct:\n            original_value = dct[k]\n            if isinstance(original_value, dict) and isinstance(v, dict):\n                # Recursive call to dict merge in order to merge sub-dict found in parent dict.\n                dict_merge(original_value, v)\n                continue\n        dct[k] = v\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger","title":"logger","text":"<p>Homemade logger.</p> <p>This module introduce some environment variables to customize the logs:</p> <pre><code>* prefix_LOG_LEVEL=TRACE..CRITICAL or trace..critical or 0..5\n    | The default log level is ``info``.\n    | Log levels in digits could be used to quickly type prefix_LOG_FILTER variable.\n* prefix_LOG_BACKEND=stdout(default if omitted)|stderr|file|syslog\n    Destination of the logs.\n* prefix_LOG_FILTER=\"&lt;level1&gt;:&lt;regex1&gt;|...|&lt;levelN&gt;:&lt;regexN&gt;\"\n    | Choose the log level per logger name.\n    | It's even possible to use regexp on module names to group loggers. Ex:\n    |   *prefix_LOG_FILTER=\"2:.*pattern1.*|5:.*pattern2.*|3:exact_module_name\"*\n    | The *.** before and after the pattern are facultative as the regexp matching is done on any inner part of the\n    | logger name.\n* prefix_LOG_COLOR=always|auto(default if omitted)|never\n    Colorize the output.\n* prefix_LOG_FILE=&lt;path&gt;\n    | Path on the system of the output file.\n    | prefix_LOG_BACKEND=file is optional in this case.\n* prefix_LOG_FORMAT=json(default if omitted)|debug|rich(if package is installed)\n    Format the logs in JSON or in a format more suitable for developers.\n* DEBUG=1\n    To avoid playing with file descriptors (to through low level logs) which is problematic in pdb sessions.\n</code></pre> <p>Activate these functionalities by calling :meth:<code>configure_logs</code> with the desired prefix in argument. When not providing any prefix, use LOG_LEVEL=TRACE..CRITICAL, etc.</p>"},{"location":"api_reference/generic_library/#generic_lib.logger.UnmergedExtraLogRecord","title":"UnmergedExtraLogRecord","text":"<pre><code>UnmergedExtraLogRecord(*args, extra=None, **kwargs)\n</code></pre> <p>             Bases: <code>LogRecord</code></p> <p>Hold extra in a <code>LogRecord</code>.</p> <p>Add extra in a seperated variable instead merging them into LogRecord.dict to loop on them easily and display all extra instead of picking some from the string format.</p> <p>I would have been possible to find extra by excluding the other LogRecord attributes, but we risk maintenance issues.</p> <p>Limitation: extra set with info(\"message\", extra={...}) won't be displayed if using the root logger or is using getLogger() before calling configure_logs(). To find these issues, use DEBUG=1 environment variable.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def __init__(self, *args, extra=None, **kwargs) -&gt; None:\n    super().__init__(*args, **kwargs)\n    self.extra = extra or {}\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.ForwardExtraLogger","title":"ForwardExtraLogger","text":"<p>             Bases: <code>Logger</code></p> <p>Logger using :class:<code>UnmergedExtraLogRecord</code>.</p>"},{"location":"api_reference/generic_library/#generic_lib.logger.ExtraTextFormatter","title":"ExtraTextFormatter","text":"<pre><code>ExtraTextFormatter()\n</code></pre> <p>             Bases: <code>Formatter</code></p> <p>Formatter providing default values for extra metadata, avoiding exceptions when not logging in json.</p> <p>The user no more needs to use a :class:<code>logging.LoggerAdapter</code>. In python&lt;=3.5, it also guarantees the order of extra metadata when using a simple dict when logging.</p> <p>Use a default log format.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Use a default log format.\"\"\"\n    super().__init__(fmt=DEBUG_LOG_FORMAT)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.ExtraTextFormatter.format","title":"format","text":"<pre><code>format(record)\n</code></pre> <p>Set the \"extra\" string before formatting the log.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def format(self, record):\n    \"\"\"Set the \"extra\" string before formatting the log.\"\"\"\n    extra = join_extra(record)\n    extra = \" \".join(\n        (f\"{kv[0]}:{kv[1]}\" for kv in self._collect_extra_leaves(extra)),\n    )\n    if extra:\n        extra += \" \"\n    record.serialized_extra = extra\n    return logging.Formatter.format(self, record)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.ColorTextFormatter","title":"ColorTextFormatter","text":"<pre><code>ColorTextFormatter()\n</code></pre> <p>             Bases: <code>ExtraTextFormatter</code></p> <p>Log formatter to colorize the logs.</p> <p>Use a default log format.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Use a default log format.\"\"\"\n    super().__init__(fmt=DEBUG_LOG_FORMAT)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.ColorTextFormatter.format","title":"format","text":"<pre><code>format(record)\n</code></pre> <p>Colorize the logs.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def format(self, record):\n    \"\"\"Colorize the logs.\"\"\"\n    return LOG_COLORS[record.levelname] % ExtraTextFormatter.format(self, record)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.JsonFormatter","title":"JsonFormatter","text":"<p>             Bases: <code>Formatter</code></p> <p>Format the logs in json with GMT iso8601 dates with nano seconds.</p>"},{"location":"api_reference/generic_library/#generic_lib.logger.JsonFormatter.format_time_ns","title":"format_time_ns  <code>staticmethod</code>","text":"<pre><code>format_time_ns(s, ns)\n</code></pre> <p>Return the current time as GMT iso8601 formatted text with nano seconds.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>@staticmethod\ndef format_time_ns(s: int, ns: int) -&gt; str:\n    \"\"\"Return the current time as GMT iso8601 formatted text with nano seconds.\"\"\"\n    ct = gmtime(s)\n    txt = strftime(\"%Y-%m-%dT%H:%M:%S\", ct)\n    return f\"{txt}.{ns:09.0f}Z\"\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.JsonFormatter.json_default","title":"json_default  <code>staticmethod</code>","text":"<pre><code>json_default(x)\n</code></pre> <p>Use python representation in case json serialization failed with specialized libraries.</p> <p>Risking encoding issues...</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>@staticmethod\ndef json_default(x: dict | OrderedDict):\n    \"\"\"Use python representation in case json serialization failed with specialized libraries.\n\n    Risking encoding issues...\n    \"\"\"\n    return repr(x)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.JsonFormatter.json_serializer","title":"json_serializer","text":"<pre><code>json_serializer(log)\n</code></pre> <p>Json serializer with low performances.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def json_serializer(self, log):\n    \"\"\"Json serializer with low performances.\"\"\"\n    return json.dumps(log, default=self.json_default)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.JsonFormatter.format_tb","title":"format_tb  <code>staticmethod</code>","text":"<pre><code>format_tb(tb)\n</code></pre> <p>Format python traceback for json logging.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>@staticmethod\ndef format_tb(tb):\n    \"\"\"Format python traceback for json logging.\"\"\"\n    stack_summary: StackSummary = StackSummary.extract(\n        walk_tb(tb),\n        capture_locals=True,\n    )\n    frame: FrameSummary  # noqa: F842\n    # Ignore frame.locals to respect security requirements.\n    return [\n        {\n            \"file\": frame.filename,\n            \"instruction\": frame.line,\n            \"line\": frame.lineno,\n            \"method\": frame.name,\n        }\n        for frame in stack_summary\n    ]\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.JsonFormatter.format_exception","title":"format_exception  <code>staticmethod</code>","text":"<pre><code>format_exception(e)\n</code></pre> <p>Format python exception for json logging.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>@staticmethod\ndef format_exception(e: type[BaseException]):\n    \"\"\"Format python exception for json logging.\"\"\"\n    formatted_exception = {\n        \"name\": e.__class__.__name__,\n        \"message\": repr(e),\n        # We could pass in parameter record.exc_info[2] to avoid reading a private attribute\n        # but, after __context__ and __cause__ usage, one more or one less...\n        \"extendedStackTrace\": JsonFormatter.format_tb(e.__traceback__),\n    }\n\n    # It would have been preferable to reuse TracebackException.format() method to not use\n    # private members __cause__ and __context__ but instead of using it on the exception varable,\n    # we would use it on the TracebackException instance to override TracebackException.stack.format()\n    # for all causes.\n    if e.__cause__ is not None:\n        cause = e.__cause__\n    elif e.__context__ is not None and not e.__suppress_context__:\n        cause = e.__context__\n    else:\n        cause = None\n    if cause is not None:\n        formatted_exception[\"cause\"] = JsonFormatter.format_exception(cause)\n\n    return formatted_exception\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.JsonFormatter.format","title":"format","text":"<pre><code>format(record)\n</code></pre> <p>Build the json that will be logged.</p> <p>Properties are set in same order than text logs.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def format(self, record):\n    \"\"\"Build the json that will be logged.\n\n    Properties are set in same order than text logs.\n    \"\"\"\n    # don't use systematically an OrderedDict for orjson compatibility\n    log_record = {} if self.use_orjson else OrderedDict()\n\n    # Field names are specified in https://ecomptes.jira.com/wiki/spaces/DEV/pages/2228060165/Logging+-+Fields+list.\n    # Order matters to respect \"debug\" LOG_FORMAT.\n    log_record[\"level\"] = _level_name_to_json[record.levelname]\n    log_record[\"levelAsInteger\"] = record.levelno\n    log_record[\"thread\"] = record.threadName\n    created_ns = time_ns()\n    s, ns = divmod(created_ns, 10**9)\n    # The field \"time\" is supposed to be used by Fluentd to compute @timestamp field,\n    # but it seems nano seconds aren't supported.\n    log_record[\"time\"] = self.format_time_ns(s, ns)\n    # Fallback on \"instant\" fields to compute @timestamp field.\n    log_record[\"instant\"] = {\"epochSecond\": s, \"nanoOfSecond\": ns}\n\n    extra = join_extra(record)\n    extra = translate_extra(extra)\n    log_record.update(extra)\n    log_file = (\n        log_record.pop(\"real_pathname\")\n        if log_record.get(\"real_pathname\", None)\n        else record.pathname\n    )\n    log_line = (\n        log_record.pop(\"real_lineno\")\n        if log_record.get(\"real_lineno\", None)\n        else record.lineno\n    )\n\n    log_record[\"loggerName\"] = record.name\n    log_record[\"logFile\"] = log_file\n    log_record[\"logLine\"] = log_line\n    log_record[\"message\"] = record.getMessage()\n\n    exc_info = record.exc_info\n    if exc_info:\n        log_record[\"thrown\"] = self.format_exception(exc_info[1])\n\n    # Python2.7 doesn't have stack_info=True argument when logging.\n    # `record.stack_info` is a str and it's impossible to format it like the exception tracebacks.\n    if sys.version_info.major == 3 and record.stack_info:\n        log_record[\"logStackTrace\"] = self.formatStack(record.stack_info)\n\n    return self.json_serializer(log_record)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.log_level_adapter","title":"log_level_adapter","text":"<pre><code>log_level_adapter(level)\n</code></pre> <p>Convert LOG_LEVEL=2, or debug, or DEBUG to the standard log level 20.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def log_level_adapter(level: str) -&gt; int:\n    \"\"\"Convert LOG_LEVEL=2, or debug, or DEBUG to the standard log level 20.\"\"\"\n    if level.isdigit():\n        level_int = int(level) * 10\n    else:\n        level_int = logging.getLevelName(level.upper())\n        if not isinstance(level_int, int):\n            raise ValueError(\n                f\"{level!r} is not a valid log level, use {tuple(LOG_COLORS.keys())}\",\n            )\n    return level_int\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.unset_pkg_name","title":"unset_pkg_name","text":"<pre><code>unset_pkg_name()\n</code></pre> <p>Unset the prefix that will be used in environment variables like prefix_LOG_LEVEL.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def unset_pkg_name() -&gt; None:\n    \"\"\"Unset the prefix that will be used in environment variables like prefix_LOG_LEVEL.\"\"\"\n    global DEBUG, LOG_BACKEND, LOG_FILE, LOG_FILTER, LOG_FORMAT, LOG_LEVEL, LOG_COLOR  # pylint: disable=global-variable-undefined\n    DEBUG = LOG_BACKEND = LOG_FILE = LOG_FILTER = None\n    LOG_FORMAT = LOG_LEVEL = LOG_COLOR = None\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.set_pkg_name","title":"set_pkg_name","text":"<pre><code>set_pkg_name(pkg_name)\n</code></pre> <p>Set the prefix that will be used in environment variables like prefix_LOG_LEVEL.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def set_pkg_name(pkg_name) -&gt; None:\n    \"\"\"Set the prefix that will be used in environment variables like prefix_LOG_LEVEL.\"\"\"\n    global DEBUG, LOG_BACKEND, LOG_FILE, LOG_FILTER, LOG_FORMAT, LOG_LEVEL, LOG_COLOR  # pylint: disable=global-variable-undefined\n    prefix = pkg_name + \"_\" if pkg_name else pkg_name\n    DEBUG = os.getenv(prefix + \"DEBUG\")\n    LOG_FILE = os.getenv(prefix + \"LOG_FILE\")\n    LOG_BACKEND = os.getenv(prefix + \"LOG_BACKEND\", \"file\" if LOG_FILE else \"stdout\")\n    LOG_FILTER = os.getenv(prefix + \"LOG_FILTER\")\n    LOG_FORMAT = os.getenv(prefix + \"LOG_FORMAT\", \"json\")\n    LOG_LEVEL = log_level_adapter(os.getenv(prefix + \"LOG_LEVEL\", \"info\"))\n    LOG_COLOR = os.getenv(prefix + \"LOG_COLOR\", \"auto\")\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.translate_extra","title":"translate_extra","text":"<pre><code>translate_extra(extra)\n</code></pre> <p>Rename extra when using json format.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def translate_extra(extra: dict | OrderedDict):\n    \"\"\"Rename extra when using json format.\"\"\"\n    return {\n        global_json_translations.get(k, k): translate_extra(v)\n        if isinstance(v, dict)\n        else v\n        for k, v in extra.items()\n    }\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.join_extra","title":"join_extra","text":"<pre><code>join_extra(record)\n</code></pre> <p>Merge all extra together.</p> <p>The ones set while configuring the logs, and the ones set with :func:<code>update_log_extra</code>, and the ones set while logging.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def join_extra(record):\n    \"\"\"Merge all extra together.\n\n    The ones set while configuring the logs,\n    and the ones set with :func:`update_log_extra`,\n    and the ones set while logging.\n    \"\"\"\n    extra = deepcopy(global_extra)\n    # Need to deepcopy _global_extra_context to not update sub-dictionaries by reference on second dict_merge\n    extra_from_context = deepcopy(_global_extra_context.get())\n    dict_merge(extra, extra_from_context)\n    if isinstance(record, UnmergedExtraLogRecord):\n        dict_merge(extra, record.extra)\n    elif DEBUG:\n        # when logging object record.msg is not yet converted to a string\n        if record.name == \"root\":\n            record.msg = (\n                str(record.msg)\n                + \" (extra are missing as using root logger instead of logging.getLogger())\"\n            )\n        else:\n            record.msg = (\n                str(record.msg)\n                + \" (extra are missing as configure_logs() is called after the first logging.getLogger())\"\n            )\n    return extra\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.trace_from_logger","title":"trace_from_logger","text":"<pre><code>trace_from_logger(self, msg, *args, **kwargs)\n</code></pre> <p>Logs a message with level TRACE on this logger. The arguments are interpreted as for :meth:<code>~logging.debug()</code>.</p> <p>EX: logger.trace(\"Houston, we have %s\", \"personal information to log\", exc_info=1)</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def trace_from_logger(self, msg, *args, **kwargs) -&gt; None:\n    \"\"\"Logs a message with level TRACE on this logger. The arguments are interpreted as for :meth:`~logging.debug()`.\n\n    EX: logger.trace(\"Houston, we have %s\", \"personal information to log\", exc_info=1)\n    \"\"\"\n    if self.isEnabledFor(TRACE_LOG_LEVEL):\n        self._log(  # pylint: disable=protected-access\n            TRACE_LOG_LEVEL,\n            msg,\n            args,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.trace_from_logging_module","title":"trace_from_logging_module","text":"<pre><code>trace_from_logging_module(msg, *args, **kwargs)\n</code></pre> <p>Log a message with severity 'TRACE' on the root logger.</p> <p>If the logger has no handlers, call basicConfig() to add a console handler with a pre-defined format.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def trace_from_logging_module(msg, *args, **kwargs) -&gt; None:\n    \"\"\"Log a message with severity 'TRACE' on the root logger.\n\n    If the logger has no handlers, call basicConfig() to add a console handler with a pre-defined format.\n    \"\"\"\n    if len(logging.root.handlers) == 0:\n        logging.basicConfig()\n    logging.root.trace(msg, *args, **kwargs)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.except_hook","title":"except_hook","text":"<pre><code>except_hook(exc_type, exc_value, exc_traceback)\n</code></pre> <p>Log uncaught exceptions.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def except_hook(exc_type, exc_value, exc_traceback) -&gt; None:\n    \"\"\"Log uncaught exceptions.\"\"\"\n    root_logger = logging.getLogger()\n    root_logger.critical(\n        \"UNCAUGHT EXCEPTION\",\n        exc_info=(exc_type, exc_value, exc_traceback),\n    )\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.setup_handlers","title":"setup_handlers","text":"<pre><code>setup_handlers()\n</code></pre> <p>Define the log format, the log backend, ...</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def setup_handlers() -&gt; None:  # pylint: disable=too-many-branches\n    \"\"\"Define the log format, the log backend, ...\"\"\"\n    root_logger = logging.getLogger()\n    root_logger.setLevel(LOG_LEVEL)\n\n    formatter = JsonFormatter() if LOG_FORMAT == \"json\" else ExtraTextFormatter()\n\n    if \"std\" in LOG_BACKEND:  # accept stdout or stderr\n        file = getattr(sys, LOG_BACKEND)\n        if LOG_FORMAT == \"rich\":\n            # don't install rich by default, let the developer install it manually if desired\n            from rich.console import (  # pylint: disable=import-error,import-outside-toplevel\n                Console,\n            )\n            from rich.logging import (  # pylint: disable=import-error,import-outside-toplevel\n                RichHandler,\n            )\n\n            # As throw_low_level_logs() had redirected stdout, we have to precise its file descriptor\n            # to avoid \"OSError: [Errno 25] Inappropriate ioctl for device\".\n            console = Console(file=file, width=os.get_terminal_size(0).columns)\n            handler = RichHandler(\n                console=console,\n                rich_tracebacks=True,\n                tracebacks_show_locals=True,\n            )\n        else:\n            handler = logging.StreamHandler(file)\n            if LOG_FORMAT != \"json\" and (\n                LOG_COLOR == \"always\"\n                or (\n                    LOG_COLOR == \"auto\"\n                    and sys.platform != \"win32\"\n                    and handler.stream.isatty()\n                )\n            ):\n                formatter = ColorTextFormatter()\n            handler.setFormatter(formatter)\n    elif LOG_BACKEND == \"file\":\n        if not LOG_FILE:\n            print(\"please set the LOG_FILE environment variable\")  # noqa: T201\n            return\n        handler = logging.FileHandler(LOG_FILE)\n        handler.setFormatter(formatter)\n    elif LOG_BACKEND == \"syslog\":\n        handler = SysLogHandler(address=\"/dev/log\")\n        handler.setFormatter(formatter)\n    elif LOG_BACKEND == \"detect\":\n        for handler in root_logger.handlers:\n            handler.setFormatter(formatter)\n        return\n    else:\n        print(\"LOG_BACKEND should be stdout, stderr, file or syslog\")  # noqa: T201\n        return\n\n    handler.is_mine = True\n    root_logger.addHandler(handler)\n\n    # replace the default exception handler to replace sys.stderr with the newly configured LOG_BACKEND\n    sys.excepthook = except_hook\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.new_set_level","title":"new_set_level","text":"<pre><code>new_set_level(self, level=None)\n</code></pre> <p>Replaces logging.Logger.setLevel to catch logs of loggers not yet created.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def new_set_level(self, level=None) -&gt; None:\n    \"\"\"Replaces logging.Logger.setLevel to catch logs of loggers not yet created.\"\"\"\n    max_path_length = 0\n    for local_filter_str, local_regexp, local_filter_level in log_filter_list:\n        match = local_regexp.match(self.name)\n        if not match:\n            continue\n        # apply the log filter only if there is more precision than previous log filter\n        # Ex: 1:package &lt; 3:package.module\n        if len(local_filter_str) &gt;= max_path_length:\n            level = local_filter_level\n            max_path_length = len(local_filter_str)\n    # don't change the log level of logger created before configure_logs() call\n    if level is not None:\n        orig_set_level(self, level)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.new_get_logger","title":"new_get_logger","text":"<pre><code>new_get_logger(name=None)\n</code></pre> <p>Replaces logging.getLogger to catch logs of loggers not yet created.</p> <p>Returns the required logger and apply the desired log level.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def new_get_logger(name=None):\n    \"\"\"Replaces logging.getLogger to catch logs of loggers not yet created.\n\n    Returns the required logger and apply the desired log level.\n    \"\"\"\n    logger = orig_get_logger(name)\n    new_set_level(logger)\n    return logger\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.setup_log_filter","title":"setup_log_filter","text":"<pre><code>setup_log_filter()\n</code></pre> <p>Override the log level of some modules according to prefix_LOG_FILTER.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def setup_log_filter() -&gt; None:\n    \"\"\"Override the log level of some modules according to prefix_LOG_FILTER.\"\"\"\n    if not LOG_FILTER:\n        return\n\n    # initialize log_filter_list\n    try:\n        for elt in LOG_FILTER.split(\"|\") if LOG_FILTER else []:\n            (filter_level, filter_str) = elt.split(\":\")\n            log_filter_list.append(\n                (filter_str, re.compile(filter_str), log_level_adapter(filter_level)),\n            )\n    except ValueError:\n        print('try this format: prefix_LOG_FILTER=\"2:.*module1.*|5:.*module2.*\"')  # noqa: T201\n        raise\n\n    # support prefix_LOG_FILTER on new loggers\n    patch(\"logging.getLogger\", new=new_get_logger).start()\n\n    # force usage of prefix_LOG_FILTER even if someone intends to change it\n    patch.object(logging.Logger, \"setLevel\", new=new_set_level).start()\n\n    # support prefix_LOG_FILTER on old loggers\n    for name in logging.root.manager.loggerDict:  # pylint: disable=no-member\n        new_set_level(logging.getLogger(name))\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.configure_logs","title":"configure_logs","text":"<pre><code>configure_logs(pkg_name='', extra=None, json_translations=None, low_level_logs=True)\n</code></pre> <p>Configure root logger and future ones according to environment variables.</p> <p>Possible environment variables are:</p> <ul> <li>prefix_LOG_LEVEL</li> <li>prefix_LOG_BACKEND</li> <li>prefix_LOG_FILTER</li> <li>prefix_LOG_COLOR</li> <li>prefix_LOG_FILE</li> <li>prefix_LOG_FORMAT.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>pkg_name</code> <code>str | None</code> <p>Package name used as a prefix in environment variables (Ex: prefix_LOG_LEVEL), no prefix by default</p> <code>''</code> <code>extra</code> <code>OrderedDict | None</code> <p>Mapping of static extra properties that will be directly included in logs</p> <code>None</code> <code>json_translations</code> <code>OrderedDict | None</code> <p>Mapping used to rename \"extra\" in json logs             (keys are the \"extra\" names used in the code and the values are the names used in json logs)</p> <code>None</code> <code>low_level_logs</code> <code>bool | None</code> <p>True to see low level logs made with printf() in modules implemented in C/C++, False to drop them. True by default. Forced to True with environment variable DEBUG=1.</p> <code>True</code> <p>The \"extra\" properties are injected in the middle of the log as you can see in the following example.</p> <pre><code>    configure_logs(\n        extra=OrderedDict(version=\"1.0.1\")\n        extra_fmt=OrderedDict(\n            user_id=\"user_id\",\n            external_user_id=\"ext_user_id\"\n        )\n    )\n    logging.info(\"hello world\",\n                 extra={\"user_id\": 123, \"ext_user_id\": 456}\n    )\n</code></pre> <p>displays:</p> <pre><code>    {\"level\":\"INFO\",\n    \"...\":\"...\",\n    \"version\":\"1.0.1\",\"user_id\":123,\"external_user_id\":456,\n    \"...\":\"...\",\n    \"message\":\"hello world\"}\n</code></pre> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def configure_logs(\n    pkg_name=\"\",\n    extra: OrderedDict | None = None,\n    json_translations: OrderedDict | None = None,\n    low_level_logs=True,\n) -&gt; None:\n    \"\"\"Configure root logger and future ones according to environment variables.\n\n    Possible environment variables are:\n\n    * prefix_LOG_LEVEL\n    * prefix_LOG_BACKEND\n    * prefix_LOG_FILTER\n    * prefix_LOG_COLOR\n    * prefix_LOG_FILE\n    * prefix_LOG_FORMAT.\n\n    Params:\n        pkg_name (str | None): Package name used as a prefix in environment variables (Ex: prefix_LOG_LEVEL), no prefix by default\n        extra (OrderedDict | None): Mapping of static extra properties that will be directly included in logs\n        json_translations (OrderedDict | None): Mapping used to rename \"extra\" in json logs \\\n            (keys are the \"extra\" names used in the code and the values are the names used in json logs)\n        low_level_logs (bool | None): True to see low level logs made with printf() in modules implemented in C/C++, False to drop them. True by default. Forced to True with environment variable **DEBUG=1**.\n\n    The \"extra\" properties are injected in the middle of the log as you can see in the following\n    example.\n\n    ```python\n\n        configure_logs(\n            extra=OrderedDict(version=\"1.0.1\")\n            extra_fmt=OrderedDict(\n                user_id=\"user_id\",\n                external_user_id=\"ext_user_id\"\n            )\n        )\n        logging.info(\"hello world\",\n                     extra={\"user_id\": 123, \"ext_user_id\": 456}\n        )\n    ```\n\n    displays:\n\n    ```json\n\n        {\"level\":\"INFO\",\n        \"...\":\"...\",\n        \"version\":\"1.0.1\",\"user_id\":123,\"external_user_id\":456,\n        \"...\":\"...\",\n        \"message\":\"hello world\"}\n    ```\n    \"\"\"\n    global global_extra, global_json_translations  # pylint: disable=global-statement\n    if LOG_LEVEL is not None:\n        logging.debug(\n            \"not configuring the logs a second time to not not duplicate the logs\",\n        )\n        return\n\n    global_extra = extra or OrderedDict()\n    global_json_translations = json_translations or OrderedDict()\n\n    # add log level TRACE\n    logging.TRACE = TRACE_LOG_LEVEL\n    logging.addLevelName(TRACE_LOG_LEVEL, \"TRACE\")\n    logging.Logger.trace = trace_from_logger\n    logging.trace = trace_from_logging_module\n\n    set_pkg_name(pkg_name)\n    # throw_low_level_logs() before setup_handlers() because, in docker and only in docker, all logs are lost otherwise\n    if not low_level_logs:\n        throw_low_level_logs()\n\n    logging.setLoggerClass(ForwardExtraLogger)\n    setup_handlers()\n    setup_log_filter()\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.unconfigure_logs","title":"unconfigure_logs","text":"<pre><code>unconfigure_logs()\n</code></pre> <p>Revert the log configuration.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def unconfigure_logs() -&gt; None:\n    \"\"\"Revert the log configuration.\"\"\"\n    if logging.getLogger is not orig_get_logger:\n        logging.getLogger = orig_get_logger\n        logging.Logger.setLevel = orig_set_level\n\n    # delete global log context\n    update_log_extra()\n\n    # remove handlers previously added\n    root_logger = logging.getLogger()\n    for handler in root_logger.handlers:\n        if hasattr(handler, \"is_mine\"):\n            root_logger.removeHandler(handler)\n\n    logging.setLoggerClass(logging.Logger)\n    unset_pkg_name()\n\n    # remove log level TRACE\n    del logging.trace\n    del logging.Logger.trace\n    del logging.TRACE\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.is_fd_protected","title":"is_fd_protected","text":"<pre><code>is_fd_protected()\n</code></pre> <p>Safety guard to not play with file descriptor to throw low level logs.</p> <p>This protection can also be implemented by calling <code>configure_logs(low_level_logs=True)</code> from the tests. Then, the second call done by the main process (with <code>low_level_logs=False</code>) will be ignored.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def is_fd_protected():\n    \"\"\"Safety guard to not play with file descriptor to throw low level logs.\n\n    This protection can also be implemented by calling `configure_logs(low_level_logs=True)` from the tests.\n    Then, the second call done by the main process (with `low_level_logs=False`) will be ignored.\n    \"\"\"\n    return DEBUG or \"pytest\" in sys.modules or \"behave\" in sys.modules\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.throw_low_level_logs","title":"throw_low_level_logs","text":"<pre><code>throw_low_level_logs()\n</code></pre> <p>Throw out low level logs made by some modules implemented in C/C++ that use printf().</p> <p>Redirect all language C/C++ logs from stdout (file descriptor number 1) to /dev/null but keep python logs on stdout.</p> Caution <ul> <li>it breaks breakpoint() history, so use prefix_DEBUG=1 environment variable when using a python shell</li> <li>incompatible with pytest</li> </ul> <p>This is a workaround made for Pulsar, the time the log configuration is added to pulsar-client package: https://github.com/apache/pulsar/issues/4234. We prefer this workaround instead of forking the pulsar-client package.</p> <p>In the future, if we fork pulsar-client to keep warnings and errors, we will start to enable log4cxx by adding <code>cmake . -DUSE_LOG4CXX</code> in <code>pulsar-client-cpp/docker/build-wheel-file-within-docker.sh</code>.</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def throw_low_level_logs() -&gt; None:\n    \"\"\"Throw out low level logs made by some modules implemented in C/C++ that use printf().\n\n    Redirect all language C/C++ logs from stdout (file descriptor number 1) to /dev/null\n    but keep python logs on stdout.\n\n    Caution:\n        - it breaks breakpoint() history, so use prefix_DEBUG=1 environment variable when using a python shell\n        - incompatible with pytest\n\n    This is a workaround made for Pulsar, the time the log configuration is added to pulsar-client package:\n    https://github.com/apache/pulsar/issues/4234.\n    We prefer this workaround instead of forking the pulsar-client package.\n\n    In the future, if we fork pulsar-client to keep warnings and errors, we will start to enable log4cxx\n    by adding `cmake . -DUSE_LOG4CXX` in `pulsar-client-cpp/docker/build-wheel-file-within-docker.sh`.\n\n    \"\"\"\n    if is_fd_protected():\n        return\n\n    fd_no_1 = sys.stdout.fileno()  # pythonic way to do \"fd_no_1 = 1\"\n\n    # Set another fd in sys.stdout that is linked to the initial destination of stdout:\n    # - step1: create a new fd that points to the initial destination of stdout\n    #          (that can be found with `readlink /proc/self/fd/1`)\n    stdout_copy = os.dup(fd_no_1)\n    # - step2: by saving a io.TextIOWrapper in sys.stdout,\n    #          python prints will now go to `readlink /proc/self/fd/1` by using the new fd\n    sys.stdout = os.fdopen(stdout_copy, \"w\")\n\n    # Now the file descriptor N\u00b01 is no more used by python,\n    # redirect it to /dev/null to lose language C logs done with printf().\n    with open(\"/dev/null\", \"w\", encoding=\"utf-8\") as stdout_redirect:\n        os.dup2(stdout_redirect.fileno(), fd_no_1)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.logger.update_log_extra","title":"update_log_extra","text":"<pre><code>update_log_extra(**extra)\n</code></pre> <p>Use the given extra for the logs of the current asynchronous task (thread or coroutine).</p> Source code in <code>src/generic_lib/logger.py</code> <pre><code>def update_log_extra(**extra) -&gt; None:\n    \"\"\"Use the given extra for the logs of the current asynchronous task (thread or coroutine).\"\"\"\n    _global_extra_context.set(extra)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.patterns","title":"patterns","text":""},{"location":"api_reference/generic_library/#generic_lib.patterns.publish_subscribe","title":"publish_subscribe","text":""},{"location":"api_reference/generic_library/#generic_lib.patterns.publish_subscribe.Provider","title":"Provider","text":"<pre><code>Provider(*args, **kwargs)\n</code></pre> <p>Implementation of the Publish-Subscribe conversation pattern.</p> Source code in <code>src/generic_lib/patterns/publish_subscribe.py</code> <pre><code>def __init__(self, *args, **kwargs) -&gt; None:\n    super().__init__(*args, **kwargs)\n    self._observers: dict[\n        type[T],\n        list[Callable[[T], None]],\n    ] = defaultdict(list)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.patterns.publish_subscribe.Provider.subscribe","title":"subscribe","text":"<pre><code>subscribe(event_type, handler)\n</code></pre> <p>Subscribe to an event type.</p> Source code in <code>src/generic_lib/patterns/publish_subscribe.py</code> <pre><code>def subscribe(\n    self,\n    event_type: type[T],\n    handler: Callable[[T], None],\n) -&gt; None:\n    \"\"\"Subscribe to an event type.\"\"\"\n    self._observers[event_type].append(handler)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.patterns.publish_subscribe.Provider.unsubscribe","title":"unsubscribe","text":"<pre><code>unsubscribe(event_type, handler)\n</code></pre> <p>Unsubscribe to an event type.</p> Source code in <code>src/generic_lib/patterns/publish_subscribe.py</code> <pre><code>def unsubscribe(\n    self,\n    event_type: type[T],\n    handler: Callable[[T], None],\n) -&gt; None:\n    \"\"\"Unsubscribe to an event type.\"\"\"\n    self._observers[event_type].remove(handler)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.patterns.publish_subscribe.Provider._publish","title":"_publish","text":"<pre><code>_publish(event)\n</code></pre> <p>Publish an event to all subscribers.</p> Source code in <code>src/generic_lib/patterns/publish_subscribe.py</code> <pre><code>def _publish(self, event: T) -&gt; None:\n    \"\"\"Publish an event to all subscribers.\"\"\"\n    for handler in self._observers[type(event)]:\n        handler(event)\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.singleton","title":"singleton","text":"<p>Classic Singleton pattern using a metaclass.</p>"},{"location":"api_reference/generic_library/#generic_lib.singleton.Singleton","title":"Singleton","text":"<p>             Bases: <code>type</code>, <code>Generic[T]</code></p> <p>Classic Singleton pattern using a metaclass.</p>"},{"location":"api_reference/generic_library/#generic_lib.yaml","title":"yaml","text":""},{"location":"api_reference/generic_library/#generic_lib.yaml.YamlLoaderError","title":"YamlLoaderError","text":"<p>             Bases: <code>Exception</code></p> <p>Error while loading yaml files.</p>"},{"location":"api_reference/generic_library/#generic_lib.yaml.YamlLoader","title":"YamlLoader","text":"<p>Mixin generally used to instantiate a Pydantic model from one or many yaml files.</p> <p>Might be used to load configuration files coming from Kubernetes config maps and secrets.</p>"},{"location":"api_reference/generic_library/#generic_lib.yaml.YamlLoader.load_from_files","title":"load_from_files  <code>classmethod</code>","text":"<pre><code>load_from_files(*files_path)\n</code></pre> <p>Instantiate the class with the content of multiple yaml files.</p> <p>:param files_path: files to merge and load (respecting order)</p> Source code in <code>src/generic_lib/yaml.py</code> <pre><code>@classmethod\ndef load_from_files(cls, *files_path) -&gt; Any:\n    \"\"\"Instantiate the class with the content of multiple yaml files.\n\n    :param files_path: files to merge and load (respecting order)\n    \"\"\"\n    full_config: dict[str, Any] = {}\n    for file_path in files_path:\n        dict_merge(full_config, cls._load_yaml_content(file_path))\n\n    try:\n        return cls(**full_config)\n    except ValidationError as e:\n        raise YamlLoaderError(\n            f\"Wrong config file format [{files_path}]: {e}\",\n        ) from e\n</code></pre>"},{"location":"api_reference/generic_library/#generic_lib.yaml.YamlLoader._load_yaml_content","title":"_load_yaml_content  <code>staticmethod</code>","text":"<pre><code>_load_yaml_content(file_path)\n</code></pre> <p>Open and parse file.</p> <p>:param file_path: yaml file path</p> Source code in <code>src/generic_lib/yaml.py</code> <pre><code>@staticmethod\ndef _load_yaml_content(file_path: str) -&gt; dict[str, Any]:\n    \"\"\"Open and parse file.\n\n    :param file_path: yaml file path\n    \"\"\"\n    try:\n        with open(file_path, encoding=\"utf-8\") as f:\n            return yaml.safe_load(f)\n    except FileNotFoundError as e:\n        raise YamlLoaderError(f\"Cannot find config file {file_path} !\") from e\n    except (ParserError, ScannerError) as e:\n        raise YamlLoaderError(f\"Cannot parse config file {file_path} !\") from e\n</code></pre>"},{"location":"api_reference/presentation_layer/","title":"Presentation Layer","text":""},{"location":"api_reference/presentation_layer/#back.config.ApplicationConfig","title":"back.config.ApplicationConfig","text":"<p>             Bases: <code>BaseModel</code>, <code>YamlLoader</code></p> <p>Application configuration.</p>"},{"location":"api_reference/presentation_layer/#back.config.ApplicationConfig.load","title":"load  <code>cached</code> <code>classmethod</code>","text":"<pre><code>load()\n</code></pre> <p>Load the configuration files designated by <code>CONFIG_PATH</code> and <code>SECRET_CONFIG_PATH</code> environment variables and cache the configuration in memory.</p> Note <p>If no environment variables are set, loads the default configuration.</p> Source code in <code>src/back/config.py</code> <pre><code>@classmethod\n@lru_cache\ndef load(cls):\n    \"\"\"Load the configuration files designated by `CONFIG_PATH` and `SECRET_CONFIG_PATH` environment variables and cache the configuration in memory.\n\n    ???+ note\n\n        If no environment variables are set, loads the default configuration.\n    \"\"\"\n    config_paths: list[str] = []\n    for key in (\"CONFIG_PATH\", \"SECRET_CONFIG_PATH\"):\n        if key in os.environ:\n            config_paths.append(os.environ[key])\n    # Try to instantiate the model directly in case all fields have default values.\n    config = cls.load_from_files(*config_paths) if config_paths else cls()\n    log.debug(f\"loaded configuration: {config!r}\")\n    return config\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.config.ApiConfig","title":"back.config.ApiConfig","text":"<p>             Bases: <code>CamelBaseModel</code></p> <p>Web server configuration.</p>"},{"location":"api_reference/presentation_layer/#back.config.ApiConfig.port","title":"port  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>port = 8000\n</code></pre> <p>Port used to publish the backend API. Used by the frontend.</p>"},{"location":"api_reference/presentation_layer/#back.config.ApiConfig.monitoring_port","title":"monitoring_port  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>monitoring_port = 9000\n</code></pre> <p>Isolated port for monitoring features (healthcheck, metrics, changing log level, etc.). Not exposed publicly. Relying on an API Gateway to block access to the <code>/monitoring</code> path poses higher risks.</p>"},{"location":"api_reference/presentation_layer/#back.config.ApiConfig.framerate","title":"framerate  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>framerate = 30\n</code></pre> <p>Number of notification per second sent by the backend to the frontend. Could be adapted according to the turn_interval parameter.</p>"},{"location":"api_reference/presentation_layer/#back.__main__","title":"back.__main__","text":"<p>Main module executed by the Dockerfile.</p>"},{"location":"api_reference/presentation_layer/#back.__main__.MultiServer","title":"MultiServer","text":"<pre><code>MultiServer(on_shutdown, *args, **kwargs)\n</code></pre> <p>             Bases: <code>Server</code></p> <p>Server listening on one port and accepting other servers in parallel.</p> Source code in <code>src/back/__main__.py</code> <pre><code>def __init__(self, on_shutdown, *args, **kwargs) -&gt; None:\n    self.on_shutdown = on_shutdown\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.__main__.MultiServer.async_run","title":"async_run  <code>async</code>","text":"<pre><code>async_run(sockets=None)\n</code></pre> <p>Run server without creating a new event loop.</p> <p>Same implementation as <code>uvicorn.Server.run</code> but in async.</p> Source code in <code>src/back/__main__.py</code> <pre><code>async def async_run(self, sockets=None) -&gt; None:\n    \"\"\"Run server without creating a new event loop.\n\n    Same implementation as `uvicorn.Server.run` but in async.\n    \"\"\"\n    self.config.setup_event_loop()\n    await self.serve(sockets=sockets)\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.__main__.MultiServer.shutdown","title":"shutdown  <code>async</code>","text":"<pre><code>shutdown(*args, **kwargs)\n</code></pre> <p>Shutdown the server and notify the others.</p> Source code in <code>src/back/__main__.py</code> <pre><code>async def shutdown(\n    self,\n    *args,\n    **kwargs,\n) -&gt; None:  # pragma: no cover (can only be called in prod)\n    \"\"\"Shutdown the server and notify the others.\"\"\"\n    self.on_shutdown()\n    cancel_all_tasks()\n    return await super().shutdown(*args, **kwargs)\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.__main__.cancel_all_tasks","title":"cancel_all_tasks","text":"<pre><code>cancel_all_tasks(exclude_current=False)\n</code></pre> <p>Cancel all asyncio tasks to force exiting on Ctrl+C.</p> <p>Necessary only because of the game infinite loop. TODO: find cleaner solution.</p> Source code in <code>src/back/__main__.py</code> <pre><code>def cancel_all_tasks(exclude_current=False) -&gt; None:\n    \"\"\"Cancel all asyncio tasks to force exiting on Ctrl+C.\n\n    Necessary only because of the game infinite loop.\n    TODO: find cleaner solution.\n    \"\"\"\n    all_tasks = asyncio.all_tasks()\n    if exclude_current and (current_task := asyncio.current_task()):  # pragma: no cover\n        all_tasks.remove(current_task)\n    for task in all_tasks:\n        task.cancel()\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.__main__.exit_application","title":"exit_application","text":"<pre><code>exit_application()\n</code></pre> <p>Exit the application.</p> Source code in <code>src/back/__main__.py</code> <pre><code>def exit_application() -&gt; None:\n    \"\"\"Exit the application.\"\"\"\n    log.info(\"exiting the backend\")\n    for server in servers:\n        server.should_exit = True\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.__main__.main","title":"main  <code>async</code>","text":"<pre><code>main()\n</code></pre> <p>Call this entry point from the Dockerfile to launch the backend.</p> Source code in <code>src/back/__main__.py</code> <pre><code>async def main() -&gt; None:\n    \"\"\"Call this entry point from the Dockerfile to launch the backend.\"\"\"\n    app_config: ApplicationConfig = ApplicationConfig.load()\n\n    for app, port in (\n        (\"back.api.routes:app\", api_port := app_config.api.port),\n        (\n            \"back.api.monitoring:app\",\n            monitoring_port := app_config.api.monitoring_port,\n        ),\n    ):\n        # WARNING: when providing the default log_config, it disabled all existing loggers, and we loose some logs.\n        config = Config(app, host=\"0.0.0.0\", port=port, log_config=None)\n        servers.append(MultiServer(config=config, on_shutdown=exit_application))\n\n    log.info(\n        f\"the backend is ready and listen on {api_port} (API) and {monitoring_port} (monitoring)\",\n    )\n    # By using a dedicated port for monitoring features (healthcheck, metrics, changing log level, etc.),\n    # and not exposing it, the frontend can't have access to these features.\n    # Relying on an API Gateway to block access to the `/monitoring` path poses higher risks.\n    await asyncio.gather(*(server.async_run() for server in servers))\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.__main__.configure_back_logs","title":"configure_back_logs","text":"<pre><code>configure_back_logs()\n</code></pre> <p>Configure the backend logs.</p> Source code in <code>src/back/__main__.py</code> <pre><code>def configure_back_logs() -&gt; None:  # pragma: no cover (only using pytest log handlers)\n    \"\"\"Configure the backend logs.\"\"\"\n    # TODO: test features of open source loggers to avoid maintaining an home made logger.\n    #  Is json format is supported? Readable format like provided by RichHandler\n    #    (https://rich.readthedocs.io/en/latest/logging.html?highlight=handler#logging-handler)?\n    #  Is is easy to set a log context (globally, for a thread or coroutines)?\n    #  Can we filter logs for debugging? Etc.\n    #  Elastic Common Schema (ECS) logger propose to standardize field names and provide the json format.\n    #    https://www.elastic.co/guide/en/ecs-logging/python/master/installation.html\n    #  structlog propose a lot of features and is a mature project:\n    #    https://www.structlog.org/en/stable/contextvars.html\n    #  picologging from Microsoft is the last in date and it's performance oriented but features seems limited:\n    #    https://microsoft.github.io/picologging/index.html\n    configure_logs(\n        json_translations=OrderedDict(\n            {\n                # Emoji are easy to read while debugging, but avoid them in production logs.\n                # NB: can be tested with LOG_LEVEL=debug LOG_FORMAT=json pdm back.\n                \"\ud83e\udd16\": \"robot\",\n            },\n        ),\n    )\n    # Limit builtin and 3rd party modules logs.\n    for module in (\"asyncio\", \"urllib3\", \"uvicorn\"):\n        logging.getLogger(module).setLevel(logging.WARNING)\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.api","title":"back.api","text":""},{"location":"api_reference/presentation_layer/#back.api.monitoring","title":"monitoring","text":""},{"location":"api_reference/presentation_layer/#back.api.monitoring.healthcheck","title":"healthcheck  <code>async</code>","text":"<pre><code>healthcheck()\n</code></pre> <p>Healthcheck for Kubernetes that returns 200 if everything is OK.</p> <p>Eventually check dependencies (e.g. message broker, database).</p> Source code in <code>src/back/api/monitoring.py</code> <pre><code>@app.get(\"/monitoring/health\")\nasync def healthcheck() -&gt; int:\n    \"\"\"Healthcheck for Kubernetes that returns 200 if everything is OK.\n\n    Eventually check dependencies (e.g. message broker, database).\n    \"\"\"\n    # Quite simple as the backend does not depend on other service for now.\n    # We at least share the same FastAPI app with other routes to be confident the app is working correctly.\n    return 200\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.api.routes","title":"routes","text":""},{"location":"api_reference/presentation_layer/#back.api.routes.catch_disconnections","title":"catch_disconnections","text":"<pre><code>catch_disconnections(func)\n</code></pre> <p>Catch client disconnections with a decorator.</p> <p>It's to avoid having an enormous try/except or multiple ones for each interaction with the WebSocket.</p> Source code in <code>src/back/api/routes.py</code> <pre><code>def catch_disconnections(func):\n    \"\"\"Catch client disconnections with a decorator.\n\n    It's to avoid having an enormous try/except or multiple ones for each interaction with the WebSocket.\n    \"\"\"\n\n    @functools.wraps(func)\n    async def _catch_disconnections_wrapper(*args, **kwargs):\n        try:\n            return await func(*args, **kwargs)\n        except WebSocketDisconnect as e:\n            log.warning(f\"Client disconnected: {e!r}\", exc_info=True)\n            return None\n\n    return _catch_disconnections_wrapper\n</code></pre>"},{"location":"api_reference/presentation_layer/#back.api.routes.websocket_endpoint","title":"websocket_endpoint  <code>async</code>","text":"<pre><code>websocket_endpoint(websocket)\n</code></pre> <p>Start a new game by connecting to a websocket.</p> <p>We can also debug the backend without frontend by doing:</p> <pre><code>python -m websockets 'ws://localhost:8080/ws'\n</code></pre> <p>The game runs as fast as possible. Eventually slow it down by using the <code>turn_interval</code> config. Spying the game by sampling the game resources at a given framerate (see <code>framerate</code> config). Game information are communicated in JSON format by a websocket. A complete resource history is sent when the game is over.</p> Source code in <code>src/back/api/routes.py</code> <pre><code>@app.websocket(\"/ws\")\nasync def websocket_endpoint(websocket: WebSocket) -&gt; None:\n    \"\"\"Start a new game by connecting to a websocket.\n\n    We can also debug the backend without frontend by doing:\n\n    ```bash\n    python -m websockets 'ws://localhost:8080/ws'\n    ```\n\n    The game runs as fast as possible. Eventually slow it down by using the `turn_interval` config.\n    Spying the game by sampling the game resources at a given framerate (see `framerate` config).\n    Game information are communicated in JSON format by a websocket.\n    A complete resource history is sent when the game is over.\n    \"\"\"\n    log.info(\"Client connected\")\n    await websocket.accept()\n    game = Game()\n\n    @catch_disconnections\n    async def notify_front() -&gt; None:\n        while game.running:\n            await asyncio.sleep(1.0 / api_config.framerate)\n\n            # Sampling number of game resources on each frame.\n            front_msg: str = game.get_counts().json()\n\n            # Using a websocket to eventually pilot the trading strategy manually from the web client.\n            await websocket.send_text(front_msg)\n\n        # Send the complete resource history when the game is over.\n        counts_history: CountsHistory = game.get_counts_history()\n        # TODO: timeit orjson.dumps(model.dict(exclude_none=True))\n        front_msg = counts_history.json(exclude_none=True)\n        await websocket.send_text(front_msg)\n\n    # Run the game and spy the game in parallel, by sampling the inventory.\n    await asyncio.gather(game.run(), notify_front())\n\n    game.destroy()\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/","title":"Controllers","text":""},{"location":"api_reference/game_domain_layer/controllers/#back.controllers","title":"back.controllers","text":""},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game","title":"game","text":""},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game.Game","title":"Game","text":"<pre><code>Game()\n</code></pre> <p>             Bases: <code>GameStatsMixin</code>, <code>TradingResourceGame</code></p> <p>The foobar factory game engine.</p> Source code in <code>src/back/controllers/game.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n\n    self._player = RandomStrategyPlayer(game=self)\n\n    # Observe initial robots.\n    for robot in self._inventory.robots:\n        robot.subscribe(Transaction, self._on_new_transaction)\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game.Game._on_new_transaction","title":"_on_new_transaction","text":"<pre><code>_on_new_transaction(transaction)\n</code></pre> <p>Receive a transaction made by robots.</p> <p>For example, a robot trades euros and foos to buy a new robot. Transactions reflects new game states.</p> <p>The game engine historicizes the transactions and propose to the player to pilot its robots. The player will have to elaborate a good strategy to accumulate new robots as fast as possible.</p> Source code in <code>src/back/controllers/game.py</code> <pre><code>def _on_new_transaction(self, transaction: Transaction) -&gt; None:\n    \"\"\"Receive a transaction made by robots.\n\n    For example, a robot trades euros and foos to buy a new robot.\n    Transactions reflects new game states.\n\n    The game engine historicizes the transactions and propose to the player\n    to pilot its robots. The player will have to elaborate a good strategy\n    to accumulate new robots as fast as possible.\n    \"\"\"\n    super()._on_new_transaction(transaction)\n\n    # Observe new robots.\n    for model in transaction.add:\n        match model:\n            case Robot():\n                model.subscribe(Transaction, self._on_new_transaction)\n\n    # Control when the inventory gets updated.\n    self._inventory.on_new_transaction(transaction)\n\n    # Eventually stop the game.\n    if len(self._inventory.robots) &gt;= game_config.max_robots:\n        self.running = False\n        return\n\n    # Once the inventory is updated, propose to the player to play, make orders.\n    self._player.trade_in_live()\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game.Game.run","title":"run  <code>async</code>","text":"<pre><code>run()\n</code></pre> <p>Start the game engine. The game ends when reaching max_robots.</p> Source code in <code>src/back/controllers/game.py</code> <pre><code>async def run(self) -&gt; None:\n    \"\"\"Start the game engine. The game ends when reaching [max_robots][back.config.GameConfig.max_robots].\"\"\"\n    # Player plays for the first time.\n    self._player.trade_in_live()\n\n    while self.running:\n        self._start_next_turn()\n        # Even if turn_interval=0, we need to wait to not block the main asyncio loop and\n        # to abort the program on Ctrl+C.\n        await asyncio.sleep(game_config.turn_interval / 1000)\n\n    # Abort planned tasks when the game is over.\n    scheduler.abort_tasks()\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game.Game._start_next_turn","title":"_start_next_turn","text":"<pre><code>_start_next_turn()\n</code></pre> <p>Perform a turn by executing all scheduled tasks.</p> <p>Generated sub-tasks will be executed in the next turn.</p> Source code in <code>src/back/controllers/game.py</code> <pre><code>def _start_next_turn(self) -&gt; None:\n    \"\"\"Perform a turn by executing all scheduled tasks.\n\n    Generated sub-tasks will be executed in the next turn.\n    \"\"\"\n    if busy_until := scheduler.busy_until:\n        # Execute all tasks by jumping to the last task timestamp.\n        scheduler.set_timestamp(busy_until)\n    else:  # pragma: no cover (dead code is no bug...)\n        log.critical(\"\u26d4 The game has deadlock... Aborting.\")\n        log.critical(f\"Final counts: {self.get_counts()}\")\n        self.running = False\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game.Game.destroy","title":"destroy","text":"<pre><code>destroy()\n</code></pre> <p>Destroy the game to avoid memory leaks \ud83d\ude05.</p> Source code in <code>src/back/controllers/game.py</code> <pre><code>def destroy(self) -&gt; None:\n    \"\"\"Destroy the game to avoid memory leaks \ud83d\ude05.\"\"\"\n    self.running = False\n    scheduler.reset()\n    self._player.destroy()\n    self._transactions[:] = []\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game_stats_mixin","title":"game_stats_mixin","text":""},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game_stats_mixin.GameStatsMixin","title":"GameStatsMixin","text":"<pre><code>GameStatsMixin()\n</code></pre> <p>             Bases: <code>TradingResourceGame</code></p> <p>Provides statistics on the game.</p> <p>Activate this mixin according to user interface needs.</p> Source code in <code>src/back/controllers/trading_resource_game.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n    self._inventory: Inventory = Inventory()\n\n    # Transactions are like \"gold source\" outputs of the game.\n    self._transactions: list[Transaction] = []\n\n    # Declare one initial transaction to inform available resources at the beginning of the game.\n    TradingResourceGame._on_new_transaction(\n        self,\n        Transaction(add=list(self._inventory.robots)),\n    )\n\n    self.running: bool = True\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game_stats_mixin.GameStatsMixin.get_counts","title":"get_counts","text":"<pre><code>get_counts()\n</code></pre> <p>Return the current resource counts.</p> Source code in <code>src/back/controllers/game_stats_mixin.py</code> <pre><code>def get_counts(self) -&gt; Counts:\n    \"\"\"Return the current resource counts.\"\"\"\n    inventory = self._inventory\n    return Counts(  # type: ignore\n        ts=scheduler.ts,\n        foo=len(inventory.foos),\n        bar=len(inventory.bars),\n        foobar=len(inventory.foobars),\n        robot=len(inventory.robots),\n        money=inventory.money.value,\n    )\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.game_stats_mixin.GameStatsMixin.get_counts_history","title":"get_counts_history","text":"<pre><code>get_counts_history()\n</code></pre> <p>Return a list of resource counts over time.</p> Source code in <code>src/back/controllers/game_stats_mixin.py</code> <pre><code>def get_counts_history(self) -&gt; CountsHistory:\n    \"\"\"Return a list of resource counts over time.\"\"\"\n    counts_history: CountsHistory = CountsHistory()\n    for transaction in self._transactions:\n        if len(counts_history) == 0:\n            new_counts = Counts(ts=0, foo=0, bar=0, foobar=0, robot=0, money=0)  # type: ignore\n            new_counts.update(transaction)\n            counts_history.append(new_counts)\n        else:\n            last_counts = counts_history[-1]\n            new_counts = last_counts.model_copy(deep=True)\n            new_counts.update(transaction)\n            assert new_counts.ts == transaction.ts\n            if last_counts.ts == new_counts.ts:\n                counts_history[-1] = new_counts\n            else:\n                counts_history.append(new_counts)\n\n    # We can display the returned data in color with:\n    # from rich import print_json\n    #\n    # print_json(data=counts_history.dict(exclude_none=True))\n    return counts_history\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.player","title":"player","text":""},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.player.Player","title":"Player","text":"<p>Mining gamer or trader, that is the question...</p>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.player.RandomStrategyPlayer","title":"RandomStrategyPlayer","text":"<pre><code>RandomStrategyPlayer(game)\n</code></pre> <p>             Bases: <code>Player</code></p> <p>Player that plays randomly.</p> <p>Many random games might help finding good strategies. Based of many observations, a random forest predictor could find correlations between some variables and elaborate a strategy. Even if decision trees are a dead ends, the random strategy is an element of comparison with strategies elaborated by humans, classic machine learning algorithms and deep learning.</p> Source code in <code>src/back/controllers/player.py</code> <pre><code>def __init__(self, game: \"Game\") -&gt; None:\n    self._game: Game | None = game\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.player.RandomStrategyPlayer.destroy","title":"destroy","text":"<pre><code>destroy()\n</code></pre> <p>Destructor method.</p> <p>Not using <code>__del__</code> because it notifies when the object is garbage collected, but it may not be called with cyclic references. It's not deterministic, so it's not compatible to avoid memory leaks. In cpython, <code>__del__</code> is in practice called when there is no more reference to the object, but with PyPy it's delayed for performances.</p> Source code in <code>src/back/controllers/player.py</code> <pre><code>def destroy(self) -&gt; None:\n    \"\"\"Destructor method.\n\n    Not using `__del__` because it notifies when the object is garbage collected,\n    but it may not be called with cyclic references. It's not deterministic, so it's not\n    compatible to avoid memory leaks.\n    In cpython, `__del__` is in practice called when there is no more reference to the object,\n    but with PyPy it's delayed for performances.\n    \"\"\"\n    self._game = None\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.player.RandomStrategyPlayer.trade_in_live","title":"trade_in_live","text":"<pre><code>trade_in_live()\n</code></pre> <p>Play each time the game changes.</p> Source code in <code>src/back/controllers/player.py</code> <pre><code>def trade_in_live(self) -&gt; None:\n    \"\"\"Play each time the game changes.\"\"\"\n    if (game := self._game) is None:\n        log.warning(\"The game is detached fom the player.\")\n        return\n    inventory = game.get_inventory()\n    for robot in inventory.robots:\n        if robot.action != Action.WAITING_FOR_ORDER:\n            continue\n\n        # It's always possible to mine foo or bar.\n        possible_actions = [robot.mine_foo, robot.mine_bar]\n\n        # Can we forge a foobar?\n        if inventory.get_foo(lock=False) and inventory.get_bar(lock=False):  # type: ignore\n            possible_actions.append(robot.forge_foobar)\n\n        # Can we sell a random count of foobar?\n        sell_count = randint(1, game_config.sell_foobar_max_count)\n        if inventory.get_foobars(count=sell_count, lock=False):  # type: ignore\n            possible_actions.append(partial(robot.sell_foobar, count=sell_count))\n\n        # Can we buy a robot?\n        if inventory.money &gt;= game_config.money_for_robot and inventory.get_foos(  # type: ignore\n            count=game_config.foo_for_robot,\n            lock=False,\n        ):\n            possible_actions.append(robot.buy_robot)\n\n        # Choose a random action that respect game rules.\n        random_action = choice(possible_actions)\n        log.debug(\n            f\"player choose {random_action} while {inventory}\",\n            extra={\"\ud83e\udd16\": robot.id},\n        )\n        random_action()\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot","title":"robot","text":""},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Action","title":"Action","text":"<p>             Bases: <code>StrEnum</code></p> <p>Robot activities or states.</p>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot","title":"Robot","text":"<pre><code>Robot(inventory, *args, **kwargs)\n</code></pre> <p>             Bases: <code>Provider</code>, <code>IncrIdRessource</code></p> <p>Hard-working robot at the mercy of the player.</p> <p>Attributes:</p> Name Type Description <code>action</code> <code>Action</code> <p>The current action/state of the robot.</p> <code>previous_action</code> <code>Action</code> <p>The previous action/state of the robot.</p> Implementation strategy <p>The game engine is based solely on these two attributes.</p> <p>We could have used several variables:</p> <ul> <li>the location of the robot (on the road, foo mine)</li> <li>a state (available or busy)</li> <li>an action (move, mine, forge or sell)</li> </ul> <p>at the risk of having inconsistencies between the variables.</p> <p>As the previous action is updated automatically when the current action is changed, almost the entire game engine depends on a single variable, thus limiting risk.</p> Source code in <code>src/back/controllers/robot.py</code> <pre><code>def __init__(self, inventory: \"Inventory\", *args, **kwargs) -&gt; None:\n    super().__init__(*args, **kwargs)\n    self._log = logging.LoggerAdapter(log, extra={\"\ud83e\udd16\": self.id})\n    self._inventory = inventory\n    self._action: Action = Action.WAITING_FOR_ORDER\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot.action","title":"action  <code>property</code> <code>writable</code>","text":"<pre><code>action\n</code></pre> <p>The current action/state of the robot.</p>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot._notify_transaction","title":"_notify_transaction","text":"<pre><code>_notify_transaction(*args, **kwargs)\n</code></pre> <p>Inform observers the robot have made a transaction.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Transaction args.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Transaction kwargs.</p> <code>{}</code> Source code in <code>src/back/controllers/robot.py</code> <pre><code>def _notify_transaction(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Inform observers the robot have made a transaction.\n\n    Params:\n        *args: Transaction args.\n        **kwargs: Transaction kwargs.\n    \"\"\"\n    from back.models.transaction import Transaction\n\n    new_transaction = Transaction(*args, **kwargs)\n    self._log.debug(f\"new transaction: {new_transaction!r}\")\n    self.action = Action.WAITING_FOR_ORDER\n    self._publish(new_transaction)\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot.mine_foo","title":"mine_foo","text":"<pre><code>mine_foo()\n</code></pre> <p>Mine one foo.</p> Source code in <code>src/back/controllers/robot.py</code> <pre><code>@action_wrapper\ndef mine_foo(self) -&gt; None:\n    \"\"\"Mine one foo.\"\"\"\n    self.action = Action.MINE_FOO\n    scheduler.schedule(game_config.mine_foo_duration, self._mine_foo_callback)\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot.mine_bar","title":"mine_bar","text":"<pre><code>mine_bar()\n</code></pre> <p>Mine one bar.</p> Source code in <code>src/back/controllers/robot.py</code> <pre><code>@action_wrapper\ndef mine_bar(self) -&gt; None:\n    \"\"\"Mine one bar.\"\"\"\n    self.action = Action.MINE_BAR\n    mine_bar_duration = randint(\n        game_config.mine_bar_duration_min,\n        game_config.mine_bar_duration_max,\n    )\n    scheduler.schedule(mine_bar_duration, self._mine_bar_callback)\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot.forge_foobar","title":"forge_foobar","text":"<pre><code>forge_foobar()\n</code></pre> <p>Assemble a foobar.</p> Source code in <code>src/back/controllers/robot.py</code> <pre><code>@action_wrapper\ndef forge_foobar(self) -&gt; None:\n    \"\"\"Assemble a foobar.\"\"\"\n    self.action = Action.FORGE_FOOBAR\n    inventory = self._inventory\n    if not (foo := inventory.get_foo()):  # type: ignore\n        self._log.debug(f\"not enough foo to forge a foobar while {inventory}\")\n        self.action = Action.WAITING_FOR_ORDER\n        return\n    if not (bar := inventory.get_bar()):  # type: ignore\n        self._log.debug(f\"not enough bar to forge a foobar while {inventory}\")\n        foo.lock = False\n        self.action = Action.WAITING_FOR_ORDER\n        return\n\n    scheduler.schedule(\n        game_config.forge_foobar_duration,\n        self._forge_foobar_callback,\n        foo=foo,\n        bar=bar,\n    )\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot._forge_foobar_callback","title":"_forge_foobar_callback","text":"<pre><code>_forge_foobar_callback(foo, bar)\n</code></pre> <p>Assembling the foobar is ended. Is it a success? If not, the foobar and the foo are trashed.</p> Source code in <code>src/back/controllers/robot.py</code> <pre><code>def _forge_foobar_callback(self, foo, bar) -&gt; None:\n    \"\"\"Assembling the foobar is ended. Is it a success? If not, the foobar and the foo are trashed.\"\"\"\n    random = randint(1, 100)\n    if random &lt;= game_config.forge_foobar_success_rate:\n        self._notify_transaction(\n            add=[FooBar.build()],\n            remove=[foo, bar],\n        )\n    else:\n        bar.lock = False\n        self._notify_transaction(remove=[foo])\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot.sell_foobar","title":"sell_foobar","text":"<pre><code>sell_foobar(count)\n</code></pre> <p>Sell some foobar(s) for money.</p> <p>Parameters:</p> Name Type Description Default <code>count</code> <code>int</code> <p>The number of foobar to sell.</p> required Source code in <code>src/back/controllers/robot.py</code> <pre><code>@action_wrapper\ndef sell_foobar(self, count: int) -&gt; None:\n    \"\"\"Sell some foobar(s) for money.\n\n    Params:\n        count (int): The number of foobar to sell.\n    \"\"\"\n    if not 1 &lt;= count &lt;= game_config.sell_foobar_max_count:\n        raise SellError(\n            f\"\ud83e\udd16 N\u00b0{self.id}: count must be between 1 and {game_config.sell_foobar_max_count}\",\n        )\n    self.action = Action.SELL_FOOBAR\n    inventory = self._inventory\n    if not (foobars := inventory.get_foobars(count=count)):  # type: ignore\n        self._log.debug(\n            f\"not enough foobar(s) to sell: {count} are needed while {inventory}\",\n        )\n        self.action = Action.WAITING_FOR_ORDER\n        return\n\n    scheduler.schedule(\n        game_config.sell_foobar_duration,\n        self._sell_foobar_callback,\n        foobars=foobars,\n    )\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.Robot.buy_robot","title":"buy_robot","text":"<pre><code>buy_robot()\n</code></pre> <p>Buy a robot instantly if there is enough money and foo(s).</p> Source code in <code>src/back/controllers/robot.py</code> <pre><code>@action_wrapper\ndef buy_robot(self) -&gt; None:\n    \"\"\"Buy a robot instantly if there is enough money and foo(s).\"\"\"\n    self.action = Action.SELL_FOOBAR\n    inventory = self._inventory\n    if inventory.money &gt;= game_config.money_for_robot and (  # type: ignore\n        foos := inventory.get_foos(count=game_config.foo_for_robot)  # type: ignore\n    ):\n        # Thankfully the transactions using money is not delay, so we don't have to lock the money.\n        self._notify_transaction(\n            add=[Robot.build(inventory=inventory)],\n            remove=[Money(value=game_config.money_for_robot), *foos],\n        )\n    else:\n        if inventory.money &lt; game_config.money_for_robot:\n            self._log.debug(\n                f\"not enough money to buy a robot: {inventory.money.value}/{game_config.money_for_robot} while {inventory}\",\n            )\n        else:\n            self._log.debug(\n                f\"not enough foo(s) to buy a robot ({game_config.money_for_robot} money + {game_config.foo_for_robot} foo are needed) while {inventory}\",\n            )\n            for foo in foos:\n                foo.lock = False\n        self.action = Action.WAITING_FOR_ORDER\n        return\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.robot.action_wrapper","title":"action_wrapper","text":"<pre><code>action_wrapper(f)\n</code></pre> <p>Decorate all robot's actions with this decorator.</p> <p>This decorator refuses the order from the player or accept it with a delay in case the robot have to move to another activity.</p> Source code in <code>src/back/controllers/robot.py</code> <pre><code>def action_wrapper(f):\n    \"\"\"Decorate all robot's actions with this decorator.\n\n    This decorator refuses the order from the [player][back.controllers.player.RandomStrategyPlayer]\n    or accept it with a delay in case the robot have to move to another activity.\n    \"\"\"\n\n    @wraps(f)\n    def _action_wrapper(self, *args, **kwargs):\n        if self.action != Action.WAITING_FOR_ORDER:\n            raise RobotBusyError(\n                f\"Robot {self} can't {f.__name__} because it is not waiting for an order.\",\n            )\n\n        # Robot is at the good place, no need to move.\n        if self.previous_action.name.lower() == f.__name__:\n            return f(self, *args, **kwargs)\n\n        # The robot have to move before executing the action.\n        self.action = Action.MOVING\n        after_moving_ts = scheduler.ts + game_config.move_duration\n        scheduler.schedule(\n            game_config.move_duration,\n            # Future \"child\" schedules have to be executed directly after the move\n            # and not depend on future time shifting.\n            scheduler.from_timestamp_decorator(after_moving_ts)(f),\n            self,\n            *args,\n            **kwargs,\n        )\n        return None\n\n    return _action_wrapper\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.trading_resource_game","title":"trading_resource_game","text":""},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.trading_resource_game.TradingResourceGame","title":"TradingResourceGame","text":"<pre><code>TradingResourceGame()\n</code></pre> <p>Interface for a trading resource game.</p> <p>NB: Trading resources generates transactions.</p> Source code in <code>src/back/controllers/trading_resource_game.py</code> <pre><code>def __init__(self) -&gt; None:\n    super().__init__()\n    self._inventory: Inventory = Inventory()\n\n    # Transactions are like \"gold source\" outputs of the game.\n    self._transactions: list[Transaction] = []\n\n    # Declare one initial transaction to inform available resources at the beginning of the game.\n    TradingResourceGame._on_new_transaction(\n        self,\n        Transaction(add=list(self._inventory.robots)),\n    )\n\n    self.running: bool = True\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.trading_resource_game.TradingResourceGame.get_inventory","title":"get_inventory","text":"<pre><code>get_inventory()\n</code></pre> <p>Return the inventory of the game.</p> Source code in <code>src/back/controllers/trading_resource_game.py</code> <pre><code>def get_inventory(self) -&gt; Inventory:\n    \"\"\"Return the inventory of the game.\"\"\"\n    return self._inventory\n</code></pre>"},{"location":"api_reference/game_domain_layer/controllers/#back.controllers.trading_resource_game.TradingResourceGame._on_new_transaction","title":"_on_new_transaction","text":"<pre><code>_on_new_transaction(transaction)\n</code></pre> <p>The game is notified when a transaction of resources happens.</p> Source code in <code>src/back/controllers/trading_resource_game.py</code> <pre><code>def _on_new_transaction(self, transaction: Transaction) -&gt; None:\n    \"\"\"The game is notified when a transaction of resources happens.\"\"\"\n    self._transactions.append(transaction)\n</code></pre>"},{"location":"api_reference/game_domain_layer/game_config/","title":"Configuration","text":""},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig","title":"back.config.GameConfig","text":"<p>             Bases: <code>CamelBaseModel</code></p> <p>Game configuration.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.move_duration","title":"move_duration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>move_duration = 5000\n</code></pre> <p>Duration in milliseconds taken by the robot to change of activity.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.mine_foo_duration","title":"mine_foo_duration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mine_foo_duration = 1000\n</code></pre> <p>Duration in milliseconds taken by the robot to mine foo.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.mine_bar_duration_min","title":"mine_bar_duration_min  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mine_bar_duration_min = 500\n</code></pre> <p>Minimum duration in milliseconds taken by the robot to mine bar.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.mine_bar_duration_max","title":"mine_bar_duration_max  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mine_bar_duration_max = 2000\n</code></pre> <p>Maximum duration in milliseconds taken by the robot to mine bar.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.forge_foobar_duration","title":"forge_foobar_duration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>forge_foobar_duration = 2000\n</code></pre> <p>Duration in milliseconds taken by the robot to assemble foobar.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.forge_foobar_success_rate","title":"forge_foobar_success_rate  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>forge_foobar_success_rate = 60\n</code></pre> <p>Success rate between 0 and 100 percent to assemble foobar.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.sell_foobar_duration","title":"sell_foobar_duration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sell_foobar_duration = 10000\n</code></pre> <p>Duration in milliseconds taken by the robot to sell foobar.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.sell_foobar_max_count","title":"sell_foobar_max_count  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sell_foobar_max_count = 5\n</code></pre> <p>Maximum number of foobar to sell in one transaction.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.money_for_foobar","title":"money_for_foobar  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>money_for_foobar = 1\n</code></pre> <p>Number of euros earned to sell a foobar.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.buy_robot_duration","title":"buy_robot_duration  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>buy_robot_duration = 0\n</code></pre> <p>Duration in milliseconds taken by the robot to buy a robot.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.money_for_robot","title":"money_for_robot  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>money_for_robot = 3\n</code></pre> <p>Number of euros needed to buy a robot.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.foo_for_robot","title":"foo_for_robot  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>foo_for_robot = 6\n</code></pre> <p>Number of foo needed to buy a robot.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.min_robots","title":"min_robots  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>min_robots = 2\n</code></pre> <p>The game starts with this number of robots.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.max_robots","title":"max_robots  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>max_robots = 30\n</code></pre> <p>The game ends when reaching this number of robots.</p>"},{"location":"api_reference/game_domain_layer/game_config/#back.config.GameConfig.turn_interval","title":"turn_interval  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>turn_interval = 0\n</code></pre> <p>Interval in milliseconds between each game turn. Increase this parameter to slow down the game. Could be adapted according to the framerate parameter.</p>"},{"location":"api_reference/game_domain_layer/models/","title":"Models","text":""},{"location":"api_reference/game_domain_layer/models/#back.models","title":"back.models","text":""},{"location":"api_reference/game_domain_layer/models/#back.models.counts_history","title":"counts_history","text":""},{"location":"api_reference/game_domain_layer/models/#back.models.counts_history.Counts","title":"Counts","text":"<p>             Bases: <code>RootModel[Counter[str]]</code></p> <p>Count all resources of the game at a given timestamp.</p> Info <p>Counts are transmitted to the frontend periodically according to the framerate parameter.</p> <p>This class is a mixed between:</p> <ol> <li>collections.Counter to stores counts easily</li> <li>addict.Dict (or Munch, Easydict, AttrDict, Prodict) 3rd party libraries to access dict values as attributes</li> <li>pydantic models to serialize the object to JSON</li> </ol> Example <p>Counts can be obtained with two syntaxes.</p> <pre><code>counts = Counts()\ncounts.update(transaction)\ncounts.ts\ncounts[\"ts\"]\ncounts.foo\ncounts[\"foo\"]\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.counts_history.Counts.update","title":"update","text":"<pre><code>update(transaction)\n</code></pre> <p>Update the timestamp and the counts of game resources.</p> <p>Parameters:</p> Name Type Description Default <code>transaction</code> <code>Transaction</code> <p>The new transaction to take into account.</p> required Source code in <code>src/back/models/counts_history.py</code> <pre><code>def update(self, transaction: Transaction) -&gt; None:\n    \"\"\"Update the timestamp and the counts of game resources.\n\n    Args:\n        transaction (Transaction): The new transaction to take into account.\n    \"\"\"\n    root = self.root\n    root[\"ts\"] = transaction.ts\n    for add in transaction.add:\n        root[add.type] += add.value if type(add) is Money else 1\n    for remove in transaction.remove:\n        root[remove.type] -= remove.value if type(remove) is Money else 1\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.counts_history.CountsHistory","title":"CountsHistory","text":"<p>             Bases: <code>RootModel[list[Counts]]</code></p> <p>List of Counts all along the game.</p> Info <p>Count history is transmitted to the frontend when the game is over to update the chart with all game info.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.counts_history.CountsHistory.append","title":"append","text":"<pre><code>append(counts)\n</code></pre> <p>Add one Counts to the count history.</p> Source code in <code>src/back/models/counts_history.py</code> <pre><code>def append(self, counts: Counts) -&gt; None:\n    \"\"\"Add one [Counts][back.models.counts_history.Counts] to the count history.\"\"\"\n    self.root.append(counts)\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.errors","title":"errors","text":""},{"location":"api_reference/game_domain_layer/models/#back.models.errors.GameError","title":"GameError","text":"<p>             Bases: <code>Exception</code></p> <p>Base class for Foobartory exceptions.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.errors.RobotBusyError","title":"RobotBusyError","text":"<p>             Bases: <code>GameError</code></p> <p>The robot cannot do anything for now.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.errors.SellError","title":"SellError","text":"<p>             Bases: <code>GameError</code></p> <p>Error while selling foobars.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.inventory","title":"inventory","text":""},{"location":"api_reference/game_domain_layer/models/#back.models.inventory.Inventory","title":"Inventory","text":"<pre><code>Inventory()\n</code></pre> <p>Inventory of all game data models.</p> <p>Act as the Game controller data model, which is also the Read data store of the CQRS pattern.</p> <p>Attributes:</p> Name Type Description <code>foos</code> <code>list[Foo]</code> <p>The available foos.</p> <code>bars</code> <code>list[Bar]</code> <p>The available bars.</p> <code>foobars</code> <code>list[FooBar]</code> <p>The available foobars.</p> <code>money</code> <code>Money</code> <p>The player's money.</p> <code>robots</code> <code>list[Robot]</code> <p>The robots working in parallel.</p> <p>Methods:</p> Name Description <code>get_foo</code> <p>Get a foo with the possibility to <code>lock</code> the ressource.</p> <code>get_bar</code> <p>Get a bar with the possibility to <code>lock</code> the ressource.</p> <code>get_foobar</code> <p>Get a foobar with the possibility to <code>lock</code> the ressource.</p> <code>get_foos</code> <p>Get <code>count</code> foos with the possibility to <code>lock</code> the ressources.</p> <code>get_bars</code> <p>Get <code>count</code> bars with the possibility to <code>lock</code> the ressources.</p> <code>get_foobars</code> <p>Get <code>count</code> foobars with the possibility to <code>lock</code> the ressources.</p> <p>All these methods are created dynamically from generic methods <code>get_ressource</code> and <code>get_ressources</code>.</p> Source code in <code>src/back/models/inventory.py</code> <pre><code>def __init__(self) -&gt; None:\n    # Complete class methods.\n    for ressource_name in IncrIdRessources.__args__:  # type: ignore\n        ressource_name = ressource_name.__name__.lower()\n        setattr(\n            self,\n            \"get_\" + ressource_name,\n            partial(self.get_ressource, ressource_name),\n        )\n        setattr(\n            self,\n            f\"get_{ressource_name}s\",\n            partial(self.get_ressources, ressource_name),\n        )\n\n    # Populate the inventory with default values.\n    self.foos: list[Foo] = []\n    self.bars: list[Bar] = []\n    self.foobars: list[FooBar] = []\n    self.money = Money()\n    self.robots: list[Robot] = [\n        Robot.build(inventory=self) for _ in range(game_config.min_robots)\n    ]\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.inventory.Inventory.get_ressource","title":"get_ressource","text":"<pre><code>get_ressource(ressource_name, lock=True)\n</code></pre> <p>Get a ressource with the possibility to <code>lock</code> the ressource.</p> <p>Parameters:</p> Name Type Description Default <code>ressource_name</code> <code>Literal['foo', 'bar', 'foobar']</code> <p>The name of the ressource to get.</p> required <code>lock</code> <code>bool</code> <p>Lock the ressource to prevent other robots from using it. Defaults to True.</p> <code>True</code> Source code in <code>src/back/models/inventory.py</code> <pre><code>def get_ressource(\n    self,\n    ressource_name: Literal[\"foo\", \"bar\", \"foobar\"],\n    lock: bool = True,\n) -&gt; IncrIdRessources | None:\n    \"\"\"Get a ressource with the possibility to `lock` the ressource.\n\n    Args:\n        ressource_name (Literal[\"foo\", \"bar\", \"foobar\"]): The name of the ressource to get.\n        lock (bool, optional): Lock the ressource to prevent other robots from using it. Defaults to True.\n    \"\"\"\n    ressources = getattr(self, ressource_name + \"s\")\n    for ressource in ressources:\n        if ressource.lock:\n            continue\n        if lock:\n            ressource.lock = True\n        return ressource\n    return None\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.inventory.Inventory.get_ressources","title":"get_ressources","text":"<pre><code>get_ressources(ressource_name, count, lock=True)\n</code></pre> <p>Get <code>count</code> ressources with the possibility to <code>lock</code> the ressources.</p> <p>Parameters:</p> Name Type Description Default <code>ressource_name</code> <code>Literal['foo', 'bar', 'foobar']</code> <p>The name of the ressource to get.</p> required <code>count</code> <code>int</code> <p>The number of ressources to get.</p> required <code>lock</code> <code>bool</code> <p>Lock the ressource to prevent other robots from using it. Defaults to True.</p> <code>True</code> Source code in <code>src/back/models/inventory.py</code> <pre><code>def get_ressources(\n    self,\n    ressource_name: Literal[\"foo\", \"bar\", \"foobar\"],\n    count: int,\n    lock=True,\n) -&gt; list[IncrIdRessources]:\n    \"\"\"Get `count` ressources with the possibility to `lock` the ressources.\n\n    Args:\n        ressource_name (Literal[\"foo\", \"bar\", \"foobar\"]): The name of the ressource to get.\n        count (int): The number of ressources to get.\n        lock (bool, optional): Lock the ressource to prevent other robots from using it. Defaults to True.\n    \"\"\"\n    returned_ressources = []\n    ressources = getattr(self, ressource_name + \"s\")\n    for ressource in ressources:\n        if ressource.lock:\n            continue\n        if lock:\n            ressource.lock = True\n        returned_ressources.append(ressource)\n        if len(returned_ressources) == count:\n            break\n\n    # Revert the lock when the count is not there.\n    if len(returned_ressources) != count:\n        for ressource in returned_ressources:\n            ressource.lock = False\n        return []\n\n    return returned_ressources\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.inventory.Inventory.on_new_transaction","title":"on_new_transaction","text":"<pre><code>on_new_transaction(transaction)\n</code></pre> <p>Update the inventory after each new <code>Transaction</code>.</p> Source code in <code>src/back/models/inventory.py</code> <pre><code>def on_new_transaction(self, transaction: Transaction) -&gt; None:\n    \"\"\"Update the inventory after each new [`Transaction`][back.models.transaction.Transaction].\"\"\"\n    for model in transaction.add:\n        match model:\n            case Foo():\n                self.foos.append(model)\n            case Bar():\n                self.bars.append(model)\n            case FooBar():\n                self.foobars.append(model)\n            case Money():\n                self.money += model\n            # Uncovered branch coverage:\n            # https://github.com/pytest-dev/pytest-cov/issues/533\n            case Robot():  # pragma: no cover\n                self.robots.append(model)\n\n    for model in transaction.remove:\n        match model:\n            case Foo():\n                self.foos.remove(model)\n            case Bar():\n                self.bars.remove(model)\n            case FooBar():\n                self.foobars.remove(model)\n            case Money():  # pragma: no cover\n                self.money -= model\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources","title":"ressources","text":""},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.BaseRessource","title":"BaseRessource","text":"<p>             Bases: <code>BaseModel</code></p> <p>Base data model that can be listed in Transaction.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.BaseRessource.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs)\n</code></pre> <p>Verify at import time that all subclasses have mandatory fields.</p> <p>For example, verify the presence of the discriminator <code>type</code> necessary for parsing json representation of resources.</p> <p>What happens without this verification at import time?</p> <p>If the game finally mint/forge a new resource, we will have this error at runtime:</p> <p>Unable to extract tag using discriminator 'type'</p> Source code in <code>src/back/models/ressources.py</code> <pre><code>def __init_subclass__(cls, **kwargs):\n    \"\"\"Verify at import time that all subclasses have mandatory fields.\n\n    For example, verify the presence of the discriminator `type` necessary for parsing json representation of resources.\n\n    !!! danger \"What happens without this verification at import time?\"\n\n        If the game finally mint/forge a new resource, we will have this error at runtime:\n         &gt; Unable to extract tag using discriminator 'type'\n\n    \"\"\"\n    # __init_subclass__ avoid having to use a metaclass in this use case.\n    super().__init_subclass__(**kwargs)\n    if \"type\" not in cls.__dict__:\n        raise TypeError(f\"The class {cls.__name__} must have a 'type' field.\")\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.IncrIdRessource","title":"IncrIdRessource","text":"<p>             Bases: <code>BaseRessource</code></p> <p>Base class for all resources that require their identifiers to be incremental.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.IncrIdRessource.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type = 'incremental_id'\n</code></pre> <p>Descriminator field used to accelarate validation.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.IncrIdRessource.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id\n</code></pre> <p>Resource identifier.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.IncrIdRessource.lock","title":"lock  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lock = Field(default=False, exclude=True)\n</code></pre> <p><code>True</code> if the resource is locked and cannot be used by another robot.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.IncrIdRessource.build","title":"build  <code>classmethod</code>","text":"<pre><code>build(*args, **kwargs)\n</code></pre> <p>Build a new resource.</p> Source code in <code>src/back/models/ressources.py</code> <pre><code>@classmethod\ndef build(cls, *args, **kwargs):\n    \"\"\"Build a new resource.\"\"\"\n    return cls(*args, id=next(cls._sequence_generator), **kwargs)\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.IncrIdRessource.reset","title":"reset  <code>classmethod</code>","text":"<pre><code>reset()\n</code></pre> <p>Make future resources start with identifier 0.</p> Source code in <code>src/back/models/ressources.py</code> <pre><code>@classmethod\ndef reset(cls) -&gt; None:\n    \"\"\"Make future resources start with identifier 0.\"\"\"\n    cls._sequence_generator = count()\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.Foo","title":"Foo","text":"<p>             Bases: <code>IncrIdRessource</code></p> <p>First mintable resource of the game.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.Bar","title":"Bar","text":"<p>             Bases: <code>IncrIdRessource</code></p> <p>Second mintable resource of the game.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.FooBar","title":"FooBar","text":"<p>             Bases: <code>IncrIdRessource</code></p> <p>Result of foo and bar assembly.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.Money","title":"Money","text":"<p>             Bases: <code>BaseRessource</code></p> <p>One of the most valuable resource of the game.</p> <p>Money and foo are exchanged to buy robots.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.ressources.Money.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value = 0\n</code></pre> <p>Amount in euros.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.transaction","title":"transaction","text":""},{"location":"api_reference/game_domain_layer/models/#back.models.transaction.Transaction","title":"Transaction","text":"<pre><code>Transaction(**kwargs)\n</code></pre> <p>             Bases: <code>BaseModel</code></p> <p>Detailed information on trades made by robots.</p> <p>Serve as the primary source of game outputs (Event Sourcing pattern). Can be serialized in JSON to be exported in raw format in a database (Redis, MongoDB, recent PostgreSQL, etc.), or in a message broker, or in a lakehouse according to the desired throughput.</p> Source code in <code>src/back/models/transaction.py</code> <pre><code>def __init__(self, **kwargs) -&gt; None:\n    if \"ts\" not in kwargs:\n        kwargs[\"ts\"] = scheduler.ts\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"api_reference/game_domain_layer/models/#back.models.transaction.Transaction.ts","title":"ts  <code>instance-attribute</code>","text":"<pre><code>ts\n</code></pre> <p>Time of the transaction in milliseconds since the start of the game.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.transaction.Transaction.add","title":"add  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>add = Field(default_factory=list)\n</code></pre> <p>Resources mint/bought by the robot.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.transaction.Transaction.remove","title":"remove  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>remove = Field(default_factory=list)\n</code></pre> <p>Resources sold by the robot.</p>"},{"location":"api_reference/game_domain_layer/models/#back.models.transaction.Transactions","title":"Transactions","text":"<p>             Bases: <code>BaseModel</code></p> <p>Helper to serialize a list of transactions.</p>"},{"location":"api_reference/game_domain_layer/scheduler/","title":"Scheduler","text":""},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler","title":"back.scheduler","text":""},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler","title":"Scheduler","text":"<pre><code>Scheduler()\n</code></pre> <p>Fake delay scheduler, CPU greedy.</p> <p>The game scheduler is not based on real timestamps or real delays, enabling the scheduling of the next game turn directly after the previous one. Indeed, the primary objective of the game is the construction of a deep reinforcement learning model, and the more matches we run, the better.</p> Source code in <code>src/back/scheduler.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._ts: int = 0  # in ms from the beginning of the game\n\n    # List of scheduler tasks organized by a heap queue algorithm.\n    # heapq is not thread safe and then, more optimal than synchronisation queues (sync or async).\n    self._tasks: list[_Task] = []\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.ts","title":"ts  <code>property</code> <code>writable</code>","text":"<pre><code>ts\n</code></pre> <p>Return the current timestamp in milliseconds from the beginning of the game.</p>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.busy_until","title":"busy_until  <code>property</code>","text":"<pre><code>busy_until\n</code></pre> <p>Return the last scheduled timestamp or None if nothing is scheduled.</p>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.scheduleabs","title":"scheduleabs","text":"<pre><code>scheduleabs(timestamp, action, *args, **kwargs)\n</code></pre> <p>Schedule a new event.</p> <p>Events scheduled for the same time will be executed in a random order. This information might be useful for the player's strategy. Executing the event means executing <code>action(*args, **kwargs)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>int</code> <p>Absolute timestamp in milliseconds</p> required <code>action</code> <code>Callable[..., Any]</code> <p>Function to be executed</p> required <code>*args</code> <code>Any</code> <p>Sequence holding the positional arguments for action</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Dictionary holding the keyword arguments for action</p> <code>{}</code> Source code in <code>src/back/scheduler.py</code> <pre><code>def scheduleabs(\n    self,\n    timestamp: int,\n    action: Callable[..., Any],\n    *args: Any,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Schedule a new event.\n\n    Events scheduled for the same time will be executed in a random order.\n    This information might be useful for the player's strategy.\n    Executing the event means executing `action(*args, **kwargs)`.\n\n    Params:\n        timestamp: Absolute timestamp in milliseconds\n        action: Function to be executed\n        *args: Sequence holding the positional arguments for action\n        **kwargs: Dictionary holding the keyword arguments for action\n    \"\"\"\n    # If \"the random order\" (cf.docstring) is a problem, just add a sequence number in the _Task\n    # just after the _Task.start_ts member and use itertools.count() to generate it.\n    simplified_action = partial(action, *args, **kwargs)\n    heappush(self._tasks, _Task(start_ts=timestamp, action=simplified_action))\n    log.debug(\n        f\"scheduling at {ts_to_str(timestamp)} action {action} with args={args} and kwargs={kwargs}\",\n    )\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.schedule","title":"schedule","text":"<pre><code>schedule(delay, action, *args, **kwargs)\n</code></pre> <p>Schedule an event in a certain delay.</p> <p>Other than the relative time, the other arguments, the effect and the return value are the same as those for scheduleabs().</p> Source code in <code>src/back/scheduler.py</code> <pre><code>def schedule(\n    self,\n    delay: int,\n    action: Callable[..., Any],\n    *args,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Schedule an event in a certain delay.\n\n    Other than the relative time, the other arguments, the effect and the return value are the same as those for\n    [scheduleabs()][back.scheduler.Scheduler.scheduleabs].\n    \"\"\"\n    ts = self.ts + delay\n    self.scheduleabs(ts, action, *args, **kwargs)\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.set_timestamp","title":"set_timestamp","text":"<pre><code>set_timestamp(timestamp)\n</code></pre> <p>Accelerate (or reverse) the time with an absolute timestamp.</p> Source code in <code>src/back/scheduler.py</code> <pre><code>def set_timestamp(self, timestamp: int) -&gt; None:\n    \"\"\"Accelerate (or reverse) the time with an absolute timestamp.\"\"\"\n    while self._tasks and (action_ts := self._tasks[0].start_ts) &lt;= timestamp:\n        task: _Task = heappop(self._tasks)\n        func = task.action.func\n        self.ts = action_ts\n        log.debug(\n            f\"executing the action {func.__name__ if hasattr(func, \"__name__\") else func} planned for {ts_to_str(action_ts)}\",\n        )\n        task.action()\n    self.ts = timestamp\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.jump","title":"jump","text":"<pre><code>jump(delay)\n</code></pre> <p>Accelerate (or reverse) the time with a relative delay.</p> Source code in <code>src/back/scheduler.py</code> <pre><code>def jump(self, delay: int) -&gt; None:\n    \"\"\"Accelerate (or reverse) the time with a relative delay.\"\"\"\n    ts = self.ts + delay\n    self.set_timestamp(ts)\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.abort_tasks","title":"abort_tasks","text":"<pre><code>abort_tasks()\n</code></pre> <p>Abort all scheduled tasks.</p> Source code in <code>src/back/scheduler.py</code> <pre><code>def abort_tasks(self) -&gt; None:\n    \"\"\"Abort all scheduled tasks.\"\"\"\n    if not self._tasks:\n        return\n    log.debug(f\"aborting {len(self._tasks)} tasks\")\n    self._tasks[:] = []\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.reset","title":"reset","text":"<pre><code>reset()\n</code></pre> <p>Reset the time to zero and abort all scheduled tasks, to be able to start a new game.</p> Source code in <code>src/back/scheduler.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Reset the time to zero and abort all scheduled tasks, to be able to start a new game.\"\"\"\n    log.debug(\"resetting scheduler\")\n    self.ts = 0\n    self.abort_tasks()\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.from_timestamp_contextmanager","title":"from_timestamp_contextmanager","text":"<pre><code>from_timestamp_contextmanager(ts)\n</code></pre> <p>Accelerate (or reverse) the time temporarily with a contextmanager.</p> <p>Allow changing the current timestamp so that child schedules do not depend on future time shifting.</p> Source code in <code>src/back/scheduler.py</code> <pre><code>@contextmanager\ndef from_timestamp_contextmanager(self, ts: int):\n    \"\"\"Accelerate (or reverse) the time temporarily with a contextmanager.\n\n    Allow changing the current timestamp so that child schedules do not depend on future time shifting.\n    \"\"\"\n    orig_ts = self.ts\n    # change now timestamp\n    self.ts = ts\n    try:\n        yield\n    finally:\n        # restore now timestamp\n        self.ts = orig_ts\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.Scheduler.from_timestamp_decorator","title":"from_timestamp_decorator","text":"<pre><code>from_timestamp_decorator(ts)\n</code></pre> <p>Accelerate (or reverse) the time temporarily with a decorator.</p> <p>Allow changing the csecondsurrent timestamp so that child schedules do not depend on future time shifting.</p> Source code in <code>src/back/scheduler.py</code> <pre><code>def from_timestamp_decorator(self, ts: int):\n    \"\"\"Accelerate (or reverse) the time temporarily with a decorator.\n\n    Allow changing the csecondsurrent timestamp so that child schedules do not depend on future time shifting.\n    \"\"\"\n\n    def _from_timestamp_decorator(f):\n        @wraps(f)\n        def _from_timestamp_wrapper(*args, **kwargs):\n            with self.from_timestamp_contextmanager(ts):\n                return f(*args, **kwargs)\n\n        return _from_timestamp_wrapper\n\n    return _from_timestamp_decorator\n</code></pre>"},{"location":"api_reference/game_domain_layer/scheduler/#back.scheduler.ts_to_str","title":"ts_to_str","text":"<pre><code>ts_to_str(timestamp)\n</code></pre> <p>Convert a timestamp in milliseconds to a formatted string representing hours, minutes, seconds, and milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>int</code> <p>The timestamp in milliseconds.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A formatted string representing the timestamp in the format         \"HH:MM:SS.sss\", where HH represents hours, MM represents minutes,         SS represents seconds, and sss represents milliseconds.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ts_to_str(1 * 3600 * 1000 + 2 * 60 * 1000 + 3 * 1000 + 4)\n'01:02:03.004'\n&gt;&gt;&gt; ts_to_str(2 * 60 * 1000 + 3 * 1000 + 4)\n'02:03.004'\n&gt;&gt;&gt; ts_to_str(3 * 1000 + 4)\n'03.004'\n&gt;&gt;&gt; ts_to_str(4)\n'00.004'\n</code></pre> Source code in <code>src/back/scheduler.py</code> <pre><code>def ts_to_str(  # NB: method and docstring generated by ChatGPT.\n    timestamp: int,  # in ms\n) -&gt; str:\n    \"\"\"Convert a timestamp in milliseconds to a formatted string representing hours, minutes, seconds, and milliseconds.\n\n    Arguments:\n        timestamp (int): The timestamp in milliseconds.\n\n    Returns:\n        A formatted string representing the timestamp in the format \\\n        \"HH:MM:SS.sss\", where HH represents hours, MM represents minutes, \\\n        SS represents seconds, and sss represents milliseconds.\n\n    Examples:\n        &gt;&gt;&gt; ts_to_str(1 * 3600 * 1000 + 2 * 60 * 1000 + 3 * 1000 + 4)\n        '01:02:03.004'\n        &gt;&gt;&gt; ts_to_str(2 * 60 * 1000 + 3 * 1000 + 4)\n        '02:03.004'\n        &gt;&gt;&gt; ts_to_str(3 * 1000 + 4)\n        '03.004'\n        &gt;&gt;&gt; ts_to_str(4)\n        '00.004'\n    \"\"\"  # NB: examples tested with: pdm run python -m doctest src/back/scheduler.py\n    milliseconds = int(timestamp % 1000)\n    seconds = int((timestamp / 1000) % 60)\n    minutes = int((timestamp / (1000 * 60)) % 60)\n    hours = int((timestamp / (1000 * 60 * 60)) % 24)\n\n    # Format hours, minutes, seconds, and milliseconds\n    formatted_time: str = \"\"\n    if hours &gt; 0:\n        formatted_time += f\"{hours:02d}:\"\n    if minutes &gt; 0 or hours &gt; 0:\n        formatted_time += f\"{minutes:02d}:\"\n    formatted_time += f\"{seconds:02d}\"\n\n    # Add milliseconds if any.\n    if milliseconds &gt; 0:\n        formatted_time += f\".{milliseconds:03d}\"\n\n    return formatted_time\n</code></pre>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p>"},{"location":"development/contributing/#environment-setup","title":"Environment setup","text":""},{"location":"development/contributing/#ide-setup","title":"IDE setup","text":"<p>To format the code automatically after saving a file, we can use inotify kernel feature to launch a script that formats the code exactly as expected by the project configuration.</p> <p>For example, for Jetbrains IDE, install File  Watchers plugin. Copy python_formatter.sh available in the project root directory to a directory listed in <code>echo $PATH</code>.</p> <p>Note</p> <p><code>./python_formatter.sh -i</code> copy the file to <code>~/.local/bin/</code>.</p> <p>Then, configure the File  Watchers like this:  Unchecking all advanced options is important.</p>"},{"location":"development/contributing/#install-pdm","title":"Install PDM","text":"Linux/MacWindows <pre><code>curl -sSL https://pdm-project.org/install-pdm.py | python3 -\n</code></pre> <pre><code>(Invoke-WebRequest -Uri https://pdm-project.org/install-pdm.py -UseBasicParsing).Content | py -\n</code></pre>"},{"location":"development/contributing/#tasks","title":"Tasks","text":"<p>This project uses PDM scripts to run tasks. Their definition is in the <code>pyproject.toml</code>. Have an overview with:</p> AliasOfficial command <pre><code>pdm scripts\n</code></pre> <pre><code>pdm run -l\n</code></pre>"},{"location":"development/contributing/#development-workflow","title":"Development workflow","text":"<p>As usual:</p> <ol> <li>create a new branch: <code>git switch -c feature-or-bugfix-name</code></li> <li>edit the code and/or the documentation</li> </ol> <p>Before committing:</p> Backend workflowFrontend workflowDocumentation workflow <ol> <li>run <code>cd back/</code> to go to the backend directory</li> <li>run <code>pdm format</code> or <code>pdm format_all</code> to auto-format the code</li> <li>run <code>pdm ci</code> to:<ol> <li>check the code and the type hints</li> <li>check if the doc compiles</li> <li>run the tests</li> <li>(fix any warning)</li> </ol> </li> <li>run the frontend and check that everything looks good (see \"Frontend workflow\" tab)</li> <li>verify from time to time:<ol> <li>if we have memory leaks with <code>pdm mem_assert</code> (analyse the issue with <code>pdm mem</code>)</li> <li>if performances are deteriorating on the benchmark chart (analyse the issue with <code>pdm profile --benchmark-only -k test_game_run_benchmark</code>)</li> </ol> </li> </ol> <ol> <li>run <code>pdm back</code> from the <code>back/</code> directory, to run the backend</li> <li>run <code>npm run dev</code> from the <code>front/</code> directory, to run the frontend</li> <li>run <code>firefox http://localhost:3000</code> and check that everything looks good</li> </ol> <p>Use Firefox, not Chrome!</p> <p>Google Chrome blocks the WebSocket communication with the development Next.js server. Use Firefox instead.</p> <p>How to slow down the game and the chart rendering?</p> <p>To slow down the game and the chart rendering, you may tweak the turn_interval and the framerate parameters by editing the default values in the code, or by providing a configuration file with the <code>CONFIG_PATH</code> environment variable.</p> <ol> <li>run <code>cd back/</code> to go to the backend directory</li> <li>run <code>pdm doc</code></li> <li>go to http://localhost:8000 and check that everything looks good</li> <li>run <code>pdm doc_deploy</code> to update GitHub pages</li> </ol> <p>After committing:</p> <p>As usual:</p> <ol> <li>verify if the CI pipeline succeeds</li> <li>open a pull request</li> <li>etc.</li> </ol>"},{"location":"development/contributing/#performance-profiling","title":"Performance profiling","text":"<p>As explained in the backend workflow, you may need to understand which part of the code is consuming more time.</p> <p>The SVG generated by <code>pdm profile --benchmark-only -k test_game_run_benchmark</code> displays three information:</p> <ol> <li>the cumulative time spent in this function and all subfunctions (from invocation till exit), example: <code>15.24%</code></li> <li>the total time spent in the given function (and excluding time made in calls to sub-functions), example: <code>(8.28%)</code>, note the presence of parentheses</li> <li>the number of calls, example: <code>21x</code></li> </ol> <p>Here is the generated SVG. Open the image in a new tab and right-click to zoom in as much as necessary.</p> <p></p>"},{"location":"development/contributing/#memory-profiling","title":"Memory profiling","text":""},{"location":"coverage/","title":"Coverage report","text":""}]}